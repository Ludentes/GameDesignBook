---
title: ai-dungeon-analysis
---
# AI Dungeon - Balance Analysis (Cautionary Tale)

## 1. Game Overview

**Title:** AI Dungeon\
**Developer:** Latitude (Nick Walton)\
**Publisher:** Latitude\
**Year:** 2019 (initial release), ongoing iterations\
**Platform:** Web, iOS, Android\
**Players:** 1 (single-player), multiplayer available\
**Session Length:** Variable (minutes to hours)\
**Campaign Length:** No defined endpoint

### Setting & Premise

AI Dungeon is a text-based adventure game powered by large language models (originally GPT-2, later GPT-3 and other models). Players can create any scenario they imagine - fantasy adventures, sci-fi stories, mystery investigations, or entirely novel genres. The AI generates responses to player actions, theoretically creating infinite possibilities.

### Core Loop

**Player Input → AI Generation → Player Response → AI Generation...**

* **Player types action:** Natural language input (no commands, full sentences)
* **AI generates response:** Describes what happens, advances story
* **Player decides next action:** Based on AI's narration
* **Cycle repeats:** Theoretically endless

**No predetermined:**

* Quest objectives
* Win conditions
* Failure states
* Resource systems
* Character progression rules

***

## 2. Intended Aesthetic(s)

**Primary:** Discovery (explore limitless possibilities), Narrative (create your own stories)\
**Secondary:** Expression (imagine anything)

**Design Goal (Stated):** Create the experience where:

* Players can imagine any scenario and the AI will play along
* No limitations on what can happen
* Ultimate freedom in storytelling
* "Infinitely generated text adventure" (marketing tagline)
* Democratize creative writing/storytelling through AI

**Aesthetic Success Markers (Intended):**

* Players create scenarios they couldn't in pre-scripted games
* Stories emerge organically from player-AI interaction
* Discovery of unexpected narrative directions
* Low barrier to entry (anyone can tell stories)
* High replay value (infinite variations)

**What Actually Happened:**

* Initial excitement and novelty
* Quick descent into incoherence
* Loss of stakes and tension
* Power creep within single sessions
* Inconsistent world/character behavior
* Stories become repetitive despite "infinite" possibilities

***

## 3. Core Mechanical Systems

### LLM-Based Generation

**The Only System:**

* GPT-2 (1.5B parameters, original)
* GPT-3 (upgraded, subscription model)
* Various fine-tuned models (Mixtral, MythoMax, etc.)

**How it works:**

* Player enters text (action, dialogue, narration)
* AI continues the story based on:
  * Previous context (limited by context window)
  * Training data patterns
  * Probability distribution of next tokens
  * Temperature/randomness settings

**What AI has access to:**

* Recent story text (2k-128k tokens depending on model/subscription)
* World info (if player manually added)
* Character descriptions (if player created)
* NO mechanical systems
* NO consequence tracking
* NO resource management
* NO difficulty settings (beyond AI model choice)

### "Mechanics" (Pseudo-Systems)

**Player-Created World Info:**

* Can add persistent information (locations, characters, rules)
* AI *may* respect this information
* No enforcement mechanism
* Often ignored or contradicted by AI

**Retry/Edit:**

* Can retry AI generation (get different response)
* Can edit any text (player or AI generated)
* No limit on retries
* Essentially infinite do-overs

**"Scales" (Premium Currency):**

* Consumed for advanced features (longer outputs, retries)
* Not a game resource, a monetization mechanism
* Doesn't affect in-game balance

### What's NOT In The System

**No consequence tracking:**

* HP doesn't persist across narration
* Injuries heal spontaneously
* Death doesn't stick
* Resources don't deplete

**No difficulty system:**

* Enemies as strong/weak as AI decides moment-to-moment
* Challenges as hard/easy as narration makes them
* No consistent power levels

**No progression system:**

* Character abilities undefined or inconsistently defined
* No leveling, no advancement
* Power level drifts based on narrative

**No win/loss conditions:**

* Can't actually fail (can retry infinitely)
* Can't actually win (no defined goals unless player self-imposes)
* Story continues until player quits

***

## 4. Balance Philosophy (Or Lack Thereof)

**Core Principle:** AI Dungeon attempts **pure narrative freedom without mechanical constraints**.

The game does NOT:

* Track consequences mechanically
* Enforce consistency
* Maintain difficulty
* Balance player power
* Create scarcity
* Define success/failure
* Impose structure

Instead, it:

1. **Generates next narration** based on patterns
2. **"Yes, and"** player actions (improv comedy rule)
3. **Continues story** regardless of coherence
4. **Trusts LLM** to create engaging narrative
5. **Provides unlimited retries** if output unsatisfactory

**Designer's Philosophy (Implicit):**
"Freedom from mechanical constraints enables pure creativity and imagination. LLM can handle narrative coherence without explicit systems."

The "balance" is supposed to emerge from LLM understanding good storytelling. This is where it fails catastrophically.

***

## 5. What Balance Problems This Creates

### Problem 1: Power Creep Within Single Session

**Issue:** Player character becomes progressively more powerful without mechanical limits

**How it happens:**

* Player narrates successful action
* AI confirms success
* Player narrates more impressive action
* AI confirms success (raised baseline)
* Cycle continues, power escalates

**Example progression in one session:**

* Start: "I draw my sword"
* 10 actions later: "I summon a legion of undead warriors"
* 20 actions later: "I reshape reality with a thought"
* No mechanical resistance, just narrative drift

**Result:** Stakes evaporate. Nothing threatens an omnipotent character.

### Problem 2: Consequence Inconsistency

**Issue:** Threats and consequences don't persist

**How it happens:**

* AI generates danger ("The dragon breathes fire, burning you badly")
* Next narration: No mention of burns
* Or: Burns mentioned but don't affect abilities
* Or: Burns gone entirely

**Example:**

* Action 1: "You're grievously wounded, bleeding heavily"
* Action 2: Player types "I climb the cliff"
* AI response: "You nimbly scale the cliff face"
* Injury forgotten or inconsistently applied

**Result:** Consequences feel cosmetic. Nothing really matters.

### Problem 3: Stakes Evaporation

**Issue:** Can't actually fail

**How it happens:**

* Death doesn't stick (AI often resurrects immediately or player retries)
* Failures get success on retry
* AI often "yes and" even impossible actions
* No resource depletion to force tough choices

**Example:**

* "I jump off the cliff" → AI: "You fall to your death"
* Retry → AI: "You spread your arms and glide safely down"
* Or: "Suddenly you remember you have wings"
* Or: "A passing eagle catches you"

**Result:** Tension impossible. Player knows nothing permanent can happen.

### Problem 4: Discovery Aesthetic Breaks

**Issue:** "Infinite possibilities" becomes "repetitive patterns"

**How it happens:**

* LLM trained on fantasy fiction tropes
* Generates familiar patterns (dragons, dungeons, chosen ones)
* Novel scenarios collapse into clichés
* "Anything is possible" becomes "same things happen"

**Example:**

* Start: "I'm a sentient toaster in a cyberpunk city"
* 5 actions later: Somehow you're fighting a gang
* 10 actions later: You've discovered you're the chosen toaster
* 15 actions later: Generic action movie plot

**Result:** Discovery replaced by predictability.

### Problem 5: Choice Meaninglessness

**Issue:** All choices lead to continuation (but not necessarily success)

**How it happens:**

* Can't make wrong choice (retry until acceptable)
* Can't make right choice (no defined goals)
* Choices don't create trade-offs (no scarcity)
* Consequences don't persist (see Problem 2)

**Result:** Agency becomes cosmetic. Choices don't really matter.

***

## 6. Key Measurables (And How They Break)

### Consequence Severity

**Intended:** Narrative consequences based on story logic\
**Actual:** Drifts toward zero over session

**Measurement (attempted):**

* Death mentioned but reversed
* Injuries described but don't affect actions
* Losses stated but not enforced
* Severity depends entirely on what AI generates next turn

**Why it fails:** No mechanical system tracks and enforces consequences across turns. LLM doesn't maintain consistent state.

### Risk Frequency

**Intended:** Dangers emerge from narrative naturally\
**Actual:** Becomes cosmetic without real stakes

**Measurement:**

* AI generates threats frequently
* But threats don't feel threatening
* Death available but doesn't stick
* "Danger" becomes flavor text

**Why it fails:** If death doesn't matter (infinite retries), danger becomes performance rather than actual risk.

### Agency Scope

**Intended:** Infinite - player can attempt anything\
**Actual:** Paradoxically shrinks - choices don't matter

**Measurement:**

* Mechanically: Can type anything
* Practically: All choices lead to similar outcomes (continuation)
* No real trade-offs (no scarcity to force decisions)

**Why it fails:** Agency requires consequences. Without consequences, choice is cosmetic.

### Tension Gradient

**Intended:** Emergent from narrative flow\
**Actual:** Flatlines to zero

**Measurement:**

* Starts with possibility of tension
* Degrades as player realizes nothing enforced
* Eventually player aware they're god-mode
* No recovery of tension (system can't create real stakes)

**Why it fails:** Tension requires possibility of loss. If nothing can be permanently lost, tension impossible.

### Emotional Stakes

**Intended:** Player cares about story outcomes\
**Actual:** Vanish once system understood

**Measurement:**

* Initial sessions: Novel, engaging
* After \~1 hour: Pattern recognized
* After \~3 hours: Novelty worn off
* Long-term: Awareness that nothing matters

**Why it fails:** Can't emotionally invest in stakes you know are fake.

### Progress Type

**Intended:** Narrative progression, character development\
**Actual:** Undefined, circular, or power creep

**Measurement:**

* No clear progression axis
* Power level drifts inconsistently
* Character development contradicts itself
* "Progress" is just "more text generated"

**Why it fails:** Progress requires direction. No mechanical goals = no meaningful progress.

### Challenge Consistency

**Intended:** Challenges emerge from story naturally\
**Actual:** None - difficulty varies wildly without logic

**Measurement:**

* Same enemy easy one turn, impossible next
* Same action succeeds then fails with no explanation
* Difficulty depends on what LLM generates, not situation
* No learning curve (can't learn patterns because patterns inconsistent)

**Why it fails:** LLM doesn't maintain challenge calibration. Each generation independent.

***

## 7. Balance Mechanisms That Don't Exist (But Should)

### Missing: Consequence Tracking System

**What's needed:**

* Mechanical HP, status effects, resources
* Persistent across AI generations
* AI must respect these values
* Can't narratively ignore them

**What would fix:**

* "You're at 10% HP" → AI can't generate "you sprint up the mountain"
* "You're out of arrows" → AI can't generate "you fire another arrow"
* Actual resource scarcity creates decisions

**Why missing:** No mechanical layer beneath narrative layer.

### Missing: Failure States

**What's needed:**

* Real possibility of character death (permanent)
* Mission failure conditions
* Unrecoverable losses
* Save point system (can't retry last action)

**What would fix:**

* Death matters → tension possible
* Failure possible → success meaningful
* Losses stick → choices have weight

**Why missing:** Design philosophy prioritizes "freedom" over "challenge"

### Missing: Consistency Enforcement

**What's needed:**

* World state tracking
* Character ability definitions
* NPC behavior patterns
* Contradiction detection

**What would fix:**

* Dragon can't be friendly then hostile then friendly without explanation
* Character abilities don't drift
* World rules maintained

**Why missing:** LLM has no memory beyond context window, no logic layer

### Missing: Difficulty Calibration

**What's needed:**

* Defined challenge levels
* Enemy power tiers
* Encounter difficulty based on character power
* Adaptive difficulty with bounds

**What would fix:**

* Early enemies beatable, late enemies challenging
* Sense of progression against meaningful opposition
* Can't trivially solve all problems

**Why missing:** No system tracks player power vs. challenge level

### Missing: Resource Systems

**What's needed:**

* HP, stamina, mana, ammunition
* Scarcity that forces decisions
* Recovery mechanisms (rest, consumables)
* Trade-offs (use resource now or save?)

**What would fix:**

* Decisions matter (resource spent = not available later)
* Victory earned (used resources wisely)
* Tension maintained (might run out)

**Why missing:** Pure narrative focus rejected mechanical systems

***

## 8. How Different Player Types Experience This

### Challenge-Focused Players

**Experience:** Frustration and abandonment

**Why it fails:**

* No consistent difficulty
* Can't optimize or learn patterns
* Victory feels hollow (no real challenge overcome)
* Retry mechanic breaks any remaining challenge

**Quote (from players):** "There's no game here. It's just typing and the AI agrees."

### Narrative-Focused Players

**Experience:** Initial excitement, then disappointment

**Why it fails:**

* Stories become incoherent
* Characters behave inconsistently
* Plot threads forgotten
* Clichés emerge despite trying to avoid them

**Quote:** "It reads like a bad fanfiction that contradicts itself every paragraph."

### Discovery-Focused Players

**Experience:** Novelty wears off quickly

**Why it fails:**

* "Infinite possibilities" collapses to familiar patterns
* Can't discover real novelty (LLM trained on existing fiction)
* Surprising moments don't lead anywhere (inconsistency)
* Once you understand the trick, magic gone

**Quote:** "After a few sessions, you realize it's just Mad Libs with extra steps."

### Fellowship-Focused Players

**Experience:** (Not applicable - single player)

**Multiplayer exists but:**

* Suffers same problems as single player
* Coordination harder when no consistent world state
* Each player's narration can contradict others

***

## 9. What Went Wrong: Root Causes

### Root Cause 1: LLM Without Constraints

**The error:**
Trusting LLM to maintain game balance without mechanical framework

**Why this fails:**

* LLMs predict next tokens, don't understand game balance
* No goal function for "maintain appropriate challenge"
* "Yes, and" improv rule breaks gameplay
* Context window limits prevent long-term consistency

**Lesson:** LLMs need explicit constraints and mechanical systems to ground them

### Root Cause 2: Narrative Freedom vs. Gameplay

**The error:**
Believing pure narrative freedom creates good games

**Why this fails:**

* Games need constraints (rules, resources, consequences)
* Freedom without constraints becomes arbitrary
* Stories need structure (beginning, middle, end, stakes)
* Unlimited power makes choices meaningless

**Lesson:** Freedom in games means "interesting choices within meaningful constraints," not "anything goes"

### Root Cause 3: No Mechanical Foundation

**The error:**
Building game entirely on LLM generation without underlying systems

**Why this fails:**

* Consequences need persistence (HP, status, resources)
* Challenge needs calibration (enemy power, player power)
* Progression needs metrics (what does advancement mean?)
* Stakes need enforcement (death must matter)

**Lesson:** LLM should enhance mechanical systems, not replace them

### Root Cause 4: Infinite Retries

**The error:**
Allowing players to retry any action until satisfactory

**Why this fails:**

* Removes all failure possibility
* Eliminates consequences
* Trains players that nothing matters
* Turns game into "search for acceptable AI output"

**Lesson:** Consequences require commitment. Can't have stakes with infinite do-overs.

### Root Cause 5: No Design Vision for "Good Story"

**The error:**
Assuming LLM knows what makes story good

**Why this fails:**

* LLMs trained on all stories (good and bad)
* No way to steer toward quality
* No definition of what "good" means
* Lowest common denominator often emerges

**Lesson:** Need explicit design goals for LLM to optimize toward

***

## 10. What Could Fix AI Dungeon

### Fix 1: Add Mechanical Layer

**Implementation:**

* HP, resources, abilities as tracked values
* LLM must respect these constraints
* Can't narratively contradict mechanics
* "You're at 5 HP" → LLM generates accordingly

**Example:**

```
Player: "I attack the dragon"
System checks: Player has 50 HP, weapon deals 10 damage, dragon has 100 HP
AI generates: "You strike the dragon's scales. It roars and sweeps its tail at you."
System checks: Dragon tail attack deals 30 damage
Result: Player now at 20 HP, dragon at 90 HP
AI continues: "You stagger from the blow, blood streaming from your wounds."
```

**Benefit:** Consequences persist, stakes real

### Fix 2: Define Failure Conditions

**Implementation:**

* HP = 0 → Character death (permanent or checkpoint restart)
* Mission failure states defined upfront
* Resource depletion consequences
* Save points (can't retry last action)

**Example:**

```
Mission: Rescue the prince before sundown
Fail condition 1: Prince dies
Fail condition 2: Sundown reaches (time limit)
Fail condition 3: You die
Retry: Only from last save point, not last action
```

**Benefit:** Real possibility of loss creates tension

### Fix 3: Constrain LLM Prompting

**Implementation:**

* System prompts that enforce challenge
* "Player is struggling. Do NOT make next challenge easier."
* "This enemy IS a threat. Generate accordingly."
* "Player cannot trivially solve this. Create real obstacle."

**Example prompt:**

```
You are DMing a Dark Souls-like adventure.
Rules:
- Player character is NOT overpowered
- Enemies pose real threat
- Player must use strategy to overcome challenges
- Do NOT let player become godlike
- Maintain danger and tension
- Success must be earned, not given
```

**Benefit:** LLM guided toward maintaining balance

### Fix 4: Explicit Consequence Memory

**Implementation:**

* Separate consequence tracking from narrative
* Status effects, injuries, resource depletion stored
* LLM retrieval system for past events
* Contradiction detection

**Example:**

```
Consequence log:
- Turn 5: Player lost left arm to dragon
- Turn 12: Player out of healing potions
- Turn 18: Player owing debt to thieves guild

LLM generation check:
If AI tries to generate "you reach out your left arm"
→ Flag contradiction, regenerate
If AI tries to generate "you drink a healing potion"
→ Check inventory, if none, block generation
```

**Benefit:** Consistency maintained

### Fix 5: Bounded Progression

**Implementation:**

* Define character power levels (tiers)
* Lock certain abilities behind progression gates
* Enemies scale but remain threatful
* LLM can't grant arbitrary powers

**Example:**

```
Character Tier 1 (Level 1-5):
- Can use basic weapons
- Can cast minor spells
- Cannot fly, teleport, or reality-warp
- LLM prevented from generating these abilities

Character Tier 2 (Level 6-10):
- Unlocks advanced combat techniques
- Can cast moderate spells
- Still bound by physics
- LLM allowed moderate fantasy powers

Etc.
```

**Benefit:** Power creep prevented, progression meaningful

***

## 11. LLM Balance Lessons (Cautionary)

### Lesson 1: LLMs Don't Understand "Challenge"

**AI Dungeon shows:** LLM has no concept of appropriate difficulty. Will "yes and" anything.

**For LLM design:** Must explicitly constrain LLM to maintain challenge. Cannot rely on LLM intuiting "this should be hard."

**Implementation:** Separate challenge calibration system that LLM operates within.

### Lesson 2: Narrative Freedom Requires Mechanical Constraints

**AI Dungeon shows:** Unlimited narrative freedom kills gameplay. No stakes = no engagement.

**For LLM design:** LLM-driven stories still need mechanical foundations (HP, resources, failure states).

**Implementation:** Hybrid system - LLM for narrative, mechanical systems for consequences and balance.

### Lesson 3: Context Alone Insufficient for Consistency

**AI Dungeon shows:** Even with long context windows, LLM contradicts itself and forgets consequences.

**For LLM design:** Need explicit state tracking beyond context window. Can't trust LLM memory.

**Implementation:** Database of world state, character state, consequences. LLM queries this, doesn't generate from memory alone.

### Lesson 4: "Yes And" Kills Tension

**AI Dungeon shows:** Improv comedy rule (always accept and build) creates death spiral of escalation.

**For LLM design:** LLM must be able to say "no" or "yes, but with cost."

**Implementation:** Constrain LLM prompting to allow failure, resistance, complication rather than pure acceptance.

### Lesson 5: Players Learn System Limits

**AI Dungeon shows:** Once players realize nothing matters, engagement collapses.

**For LLM design:** Can't hide lack of consequences behind impressive prose. Players figure it out.

**Implementation:** Actually implement consequences mechanically. Don't fake it with narrative.

### Lesson 6: Retry Mechanic Breaks Stakes

**AI Dungeon shows:** Infinite retries mean nothing permanent can happen.

**For LLM design:** If allowing retries, must cost something or have limits.

**Implementation:** Limited retries, or retry costs resource, or restart from checkpoint not immediate retry.

### Lesson 7: LLM Needs Optimization Target

**AI Dungeon shows:** "Generate text that continues story" insufficient goal.

**For LLM design:** Must define what "good" means - maintain tension? Create challenge? Enforce consistency?

**Implementation:** Multi-objective optimization or explicit constraints in system prompt.

***

## 12. Comparison: AI Dungeon vs. Successful Systems

### vs. Blades in the Dark Position/Effect

**Blades:** Framework constrains GM decisions, maintains consistency\
**AI Dungeon:** No framework, LLM decides arbitrarily

**Why Blades works:** Position/Effect creates predictable risk/reward calculation\
**Why AI Dungeon fails:** No predictability, stakes drift arbitrarily

### vs. Dark Souls Consistency

**Dark Souls:** Fixed enemy patterns enable learning and mastery\
**AI Dungeon:** No patterns, nothing to learn

**Why Dark Souls works:** Consistency lets players improve\
**Why AI Dungeon fails:** Inconsistency prevents skill development

### vs. Left 4 Dead 2 Adaptive Difficulty

**L4D2:** AI Director adapts to maintain tension within bounds\
**AI Dungeon:** No bounds, adaptation drifts toward no challenge

**Why L4D2 works:** Director maintains appropriate difficulty\
**Why AI Dungeon fails:** No calibration of difficulty level

### AI Dungeon as Negative Example

What AI Dungeon teaches by failure:

1. LLMs need constraints
2. Narrative requires mechanical foundations
3. Freedom without limits becomes arbitrary
4. Stakes need enforcement
5. Consequences must persist
6. Consistency matters more than variety
7. Players need something to overcome

***

## 13. Extractable Design Principles (Negative)

### Anti-Principle 1: Don't Trust LLM Alone for Balance

**What AI Dungeon tried:** Pure LLM, no mechanical systems\
**Why it failed:** LLM has no balance intuition

**Correct approach:** LLM within mechanical framework that enforces balance

### Anti-Principle 2: Don't Confuse Freedom With Good Design

**What AI Dungeon tried:** "Anything possible" as feature\
**Why it failed:** Constraints create meaningful choices

**Correct approach:** Freedom within meaningful constraints

### Anti-Principle 3: Don't Ignore Consequence Persistence

**What AI Dungeon tried:** Narrative consequences without mechanical tracking\
**Why it failed:** Consequences forgot or contradicted

**Correct approach:** Mechanical consequences that LLM must respect

### Anti-Principle 4: Don't Allow Infinite Retries Without Cost

**What AI Dungeon tried:** Retry any action until acceptable\
**Why it failed:** Eliminated all stakes

**Correct approach:** Limited retries or retry costs resources

### Anti-Principle 5: Don't Assume Variety = Replayability

**What AI Dungeon tried:** "Infinite possibilities" through LLM generation\
**Why it failed:** Variety collapses to clichés, replayability requires meaningful different outcomes

**Correct approach:** Constrained variation that creates meaningfully different experiences

### Anti-Principle 6: Don't Build on LLM Without Foundation

**What AI Dungeon tried:** LLM as entire game\
**Why it failed:** No mechanical foundation to ground narrative

**Correct approach:** Mechanical systems first, LLM enhancement second

***

## 14. What AI Dungeon Got Right (Brief)

### Accessibility

* Text-based = low barrier to entry
* Natural language = no command memorization
* Anyone can start playing immediately

### Initial Novelty

* First exposure to LLM-generated content impressive
* Feels magical initially
* Demonstrates LLM capability

### Creative Prompting

* Players learned to craft better prompts
* Community shared techniques
* Showed potential for LLM interaction

### Multiplayer Experiments

* Showed co-creative possibilities
* Multiple players contributing to story
* (Though still plagued by consistency issues)

**These positives don't outweigh fundamental balance failures.**

***

## 15. Open Questions for LLM Game Design

### Question 1: Minimum Mechanical Requirements

**Issue:** What's minimum mechanical foundation needed for LLM game?\
**Research needed:** Test various hybrid approaches, find sweet spot

### Question 2: Constraint Optimization

**Issue:** How constraining LLM without destroying creativity?\
**Research needed:** Study different constraint types, player satisfaction

### Question 3: Consequence Detection

**Issue:** Can LLM detect its own contradictions?\
**Research needed:** Test self-consistency checking, correction mechanisms

### Question 4: Challenge Calibration

**Issue:** Can LLM maintain appropriate difficulty with prompting alone?\
**Research needed:** Test various prompt strategies, measure difficulty consistency

### Question 5: Long-Term Consistency

**Issue:** How maintain consistency across sessions beyond context window?\
**Research needed:** Test memory architectures, state tracking systems

***

## 16. Key Takeaways for "From Principles to Numbers"

### For Game Designers

**1. LLMs are tools, not solutions:**
AI Dungeon shows LLM alone insufficient. Need mechanical systems.

**2. Freedom requires constraints:**
"Anything possible" becomes "nothing matters" without boundaries.

**3. Consequences must be enforceable:**
Narrative consequences without mechanical backing don't stick.

**4. Consistency > Variety:**
Players prefer consistent challenge to random variation.

**5. Stakes require real possibility of loss:**
Can't create tension if nothing permanent can happen.

**6. Balance needs explicit design:**
Can't emerge from LLM alone. Must be designed and enforced.

### For LLM Integration

**1. Don't use LLM as only system:**
Mechanical foundation required. LLM enhances, doesn't replace.

**2. Constrain LLM explicitly:**
System prompts must enforce challenge, consistency, consequences.

**3. Track state separately:**
Can't trust LLM memory. Need dedicated state tracking.

**4. Define success/failure clearly:**
LLM needs explicit goals to optimize toward.

**5. Test for consistency:**
Detect contradictions, enforce consequence persistence.

**6. Limit retries:**
Infinite do-overs kill stakes. Failure must be possible.

### For Testing Framework

**When testing LLM-enhanced games, check:**

* Do consequences persist across LLM generations?
* Can player actually fail permanently?
* Does difficulty remain appropriate over time?
* Are contradictions detected and prevented?
* Do choices have meaningful trade-offs?
* Can player become arbitrarily powerful?

**AI Dungeon violations:**

* ❌ Consequences vanish
* ❌ Can't fail (infinite retries)
* ❌ Difficulty drifts to zero
* ❌ Rampant contradictions
* ❌ No real trade-offs
* ❌ Power creep inevitable

***

## Document Status

**Created:** November 2025\
**Purpose:** First-pass analysis of AI Dungeon as cautionary tale for balance chapter\
**Status:** Complete for initial brainstorming\
**Sources:** User reports, game design analysis, LLM research\
**Next Steps:** Use as negative example in balance framework, contrast with successful games

***

## References & Further Reading

**Game Analysis:**

* AI Dungeon user community (Reddit, Discord)
* ScreenRant: "Why AI Dungeon Is A Work In Progress, And Still Not Safe"
* Hacker News discussions on AI Dungeon's issues

**LLM Gaming Research:**

* "LLMs as Dungeon Masters: Can AI Run a Tabletop Game Without Cheating?" (DEV Community)
* GTBench research on LLM game-playing capabilities
* Studies on LLM hallucination and consistency

**Design Articles:**

* "How to Build an AI Dungeon Master for Tabletop RPGs" (Medium)
* Various articles on hybrid AI/mechanical systems

**Contrast Cases:**

* Blades in the Dark (framework-based consistency)
* Dark Souls (static consistent challenge)
* Left 4 Dead 2 (adaptive but bounded difficulty)

**Related Projects:**

* NovelAI (similar but different approach)
* Friends & Fables (hybrid AI + rules system)
* ChatGPT creative mode (LLM without game structure)
