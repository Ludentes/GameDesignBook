---
title: 13-future-research
---
# Part 13: Open Questions and Future Research

## Introduction

This book has explored cognitive load systematically: what it is, how it works, how to design with it intentionally. But many questions remain unanswered. Some are empirical (need testing), some are conceptual (need deeper analysis), some are emerging (new technologies like LLMs create new questions).

This chapter identifies:

* **Areas needing empirical research** (measurement, testing, validation)
* **Conceptual questions** (theory gaps, unclear boundaries)
* **Emerging challenges** (LLMs, accessibility, new contexts)
* **Directions for future work** (what we don't know yet)

These are not failures of the framework—they're **invitations for further exploration**.

***

## Area 1: Measuring Cognitive Load Empirically

### The Measurement Challenge

**We can theorize about cognitive load, but how do we MEASURE it?**

**Current approaches:**

**1. Self-Report (Subjective)**

* Ask players: "How mentally demanding was this?"
* NASA-TLX scale (mental demand, effort, frustration)
* **Problem:** Subjective, varies by person, affected by memory/mood

**2. Performance Metrics (Objective)**

* Task completion time (slower = higher load?)
* Error rates (more mistakes = overwhelmed?)
* Secondary task performance (can they do two things at once?)
* **Problem:** Performance ≠ load (experts perform well despite high load)

**3. Physiological Measures**

* Heart rate variability (stress indicator)
* Eye tracking (pupil dilation, fixation patterns)
* EEG (brain activity patterns)
* **Problem:** Expensive, lab-only, hard to interpret causally

**4. Behavioral Observation**

* Do players use workarounds? (wikis, spreadsheets, notes)
* Do they quit early? (overwhelm)
* Do they go on autopilot? (under-stimulation)
* **Problem:** Indirect, requires interpretation

***

### Open Questions

**Q1: Can we create standardized cognitive load scales for games?**

**Why it matters:** "This game has HIGH cognitive load" is vague. Can we quantify?

**Possible approaches:**

* Load type breakdown (simultaneity: 4/5, decision: 3/5, memory: 2/5)
* Genre-relative scales (high for party game ≠ high for RTS)
* Audience-specific norms (casual vs. hardcore expectations)

**Challenges:**

* Load is subjective (varies by player)
* Context-dependent (same game, different perceived load based on group)
* Multi-dimensional (hard to reduce to single number)

**Research needed:**

* Large-scale playtesting across player types
* Correlation between self-report and performance
* Validation across genres and contexts

***

**Q2: How do we measure load over time (learning curves)?**

**Why it matters:** Load changes as players learn. How to capture this dynamic?

**Possible approaches:**

* Repeated measures (same players, multiple sessions)
* Novice vs. expert comparison (cross-sectional)
* Learning curve modeling (mathematical functions)

**Challenges:**

* Individual variation (some learn faster)
* Retention (how much do players remember between sessions?)
* Plateau effects (when does learning stop improving?)

**Research needed:**

* Longitudinal studies (track players over weeks/months)
* Identify inflection points (when does load shift qualitatively?)
* Understand load revelation (when mastery reveals more complexity)

***

**Q3: Can we predict cognitive load from game features?**

**Why it matters:** Can designers estimate load before playtesting?

**Possible approaches:**

* Feature analysis (number of mechanics, resources, decision points)
* Complexity metrics (state space size, branching factor)
* Information theory (entropy, information rate)

**Challenges:**

* Load isn't just feature count (10 simple mechanics ≠ 10 complex ones)
* Emergent complexity (interactions create more load than sum of parts)
* Context matters (turn-based vs. real-time changes everything)

**Research needed:**

* Build predictive models (machine learning on game features?)
* Validate against empirical load measures
* Account for context and emergence

***

## Area 2: Optimal Load Curves and Flow States

### Flow Theory and Cognitive Load

**Csikszentmihalyi's Flow State:**

* Optimal experience: challenge matches skill
* Complete absorption, time distortion, intrinsic motivation
* "In the zone"

**Relationship to cognitive load:**

* Too little load = boredom (under-stimulated)
* Too much load = anxiety (overwhelmed)
* Just right = flow (engaged, challenged, capable)

**But:** Flow theory doesn't specify HOW to achieve optimal load.

***

### Open Questions

**Q4: What is the optimal cognitive load curve?**

**Why it matters:** How should load change from beginner to expert?

**Possible patterns:**

**Pattern A: Constant challenge (adaptive difficulty)**

* Load scales with skill (always at flow threshold)
* Example: Ranked matchmaking (always 50% win rate)
* **Question:** Does this create satisfaction, or just treadmill?

**Pattern B: Mastery reduction (front-load then decrease)**

* High initial load (learning), decreases with practice
* Example: Dark Souls (brutal at first, easy once learned)
* **Question:** When does reduced load become boring?

**Pattern C: Depth revelation (scales up with mastery)**

* Surface simplicity, hidden depth revealed over time
* Example: Go, Chess (simple rules, infinite tactics)
* **Question:** How to prevent intimidation or plateau frustration?

**Pattern D: Cyclical (escalate then reset)**

* Ramp up complexity, then reset for new content
* Example: Roguelikes (each run starts fresh but with more knowledge)
* **Question:** How to maintain interest across cycles?

**Research needed:**

* Longitudinal engagement studies (which curves retain players?)
* Satisfaction measures (which patterns feel most rewarding?)
* Genre differences (different curves for different game types?)

***

**Q5: Can we design for multiple flow channels simultaneously?**

**Why it matters:** Different players have different load preferences.

**Challenge:**

* Achievers want conquerable high load
* Socializers want low mechanical load
* Can one game serve both?

**Possible solutions:**

* Layered depth (simple surface, optional complexity)
* Role differentiation (different roles = different loads)
* Difficulty modes (player-selected load level)

**Research needed:**

* Which approaches work best?
* Trade-offs (does serving everyone mean serving no one well?)
* Can we detect player type in real-time and adapt?

***

**Q6: How does load relate to "fun"?**

**Why it matters:** Flow is ONE type of enjoyment. Are there others?

**MDA Aesthetics (8 types of fun):**

* Sensation, Fantasy, Narrative, Challenge, Fellowship, Discovery, Expression, Submission

**Do all require flow?**

* Challenge: Yes (flow = optimal challenge)
* Fellowship: Maybe not (socializing doesn't require perfect load balance)
* Submission: Possibly opposite (relaxation = UNDER-stimulation)

**Research needed:**

* Map load curves to aesthetic types
* Identify when flow matters vs. when other factors dominate
* Understand low-load enjoyment (not just under-stimulation)

***

## Area 3: Cognitive Accessibility

### The Accessibility Challenge

**Cognitive load affects accessibility:**

* High-load games exclude players with cognitive disabilities
* But also exclude: elderly, tired, distracted, non-native language speakers
* "Accessible" doesn't mean "dumbed down"

***

### Open Questions

**Q7: How do we design for cognitive accessibility without compromising depth?**

**Why it matters:** Games should be inclusive while maintaining challenge for those who want it.

**Possible approaches:**

* **Assistive tools:** Guides, hints, auto-play options
* **Scalable difficulty:** Player-selected load level
* **Different challenge types:** Not just cognitive (can be emotional, physical, social)
* **Universal design:** Low load baseline benefits everyone

**Challenges:**

* What's "accessible" to one is "boring" to another
* How to avoid patronizing or stigmatizing accessible modes?
* Can challenge exist without cognitive load?

**Research needed:**

* Work with cognitively disabled players (what do they actually need?)
* Test universal design principles (do they work for games?)
* Understand trade-offs (when does accessibility compromise core experience?)

***

**Q8: Can we adapt load dynamically based on player state?**

**Why it matters:** Players aren't always at peak capacity (tired, distracted, learning).

**Possible approaches:**

* **Performance monitoring:** Detect struggling, reduce load
* **Explicit feedback:** Ask player "too hard/easy?"
* **Context awareness:** Time of day, session length, recent performance
* **Physiological sensing:** (future) Heart rate, attention tracking

**Challenges:**

* Privacy concerns (monitoring player state)
* Accuracy (is poor performance = high load, or just bad luck?)
* Player agency (do they want system deciding difficulty?)

**Research needed:**

* Develop reliable load detection algorithms
* Test player reception (do they like adaptive systems?)
* Understand individual differences (what works for whom?)

***

**Q9: How do learning disabilities affect game design?**

**Why it matters:** Dyslexia, ADHD, autism spectrum, etc. interact with cognitive load uniquely.

**Considerations:**

* **Dyslexia:** Text-heavy games are high-load (need audio alternatives, simple fonts)
* **ADHD:** Simultaneity load especially challenging (need focus aids, clear priorities)
* **Autism:** Social deduction games high-load (need clear rules, not implicit social cues)

**Current state:**

* Mostly unknown (little research on games + specific disabilities)
* Anecdotal reports (some games accidentally work well, others exclude)

**Research needed:**

* Partner with disability communities (co-design)
* Test existing games for accessibility barriers
* Develop design guidelines (best practices)

***

## Area 4: LLM Capabilities and Limitations

### The LLM Question

**LLMs are NEW technology (2020s).** We don't fully understand:

* What they can/can't do reliably
* How they change game design possibilities
* What new problems they create

***

### Open Questions

**Q10: What cognitive load can LLMs reliably handle?**

**Why it matters:** We theorize LLMs can offload memory, track state, generate content. But can they, consistently?

**Hypothesized capabilities:**

* **State tracking:** Maintain world state, NPC memories (but: context limits, hallucination)
* **Content generation:** Descriptions, dialogue, complications (but: quality variance, prompt dependence)
* **Consistency maintenance:** Keep world coherent (but: can contradict itself)
* **Adaptive difficulty:** Adjust challenge (but: hard to calibrate)

**Observed limitations:**

* **Calculation:** Bad at math, logic puzzles
* **Long-term memory:** Forgets things outside context window
* **Consistency:** Can contradict previous statements
* **Transparency:** "Black box" decisions (players can't understand why)

**Research needed:**

* Systematic testing (what works, what fails?)
* Benchmarking (measure consistency, creativity, coherence)
* Best practices (how to prompt for reliable results?)

***

**Q11: Do LLMs reduce or increase player cognitive load?**

**Why it matters:** We assume LLMs help. Do they?

**Potential load REDUCTION:**

* Offload memory (LLM remembers, player doesn't need to)
* Just-in-time info (surface relevant details when needed)
* Natural language interface (no complex UI to learn)

**Potential load INCREASE:**

* **Choice paralysis:** Infinite options (LLM can generate anything)
* **Ambiguity:** Unclear what's possible (no explicit rules)
* **Trust issues:** Can I trust LLM's consistency?
* **Meta-cognition:** Figuring out how to interact with LLM itself

**Research needed:**

* A/B testing (LLM-assisted vs. traditional systems)
* Measure actual load (not just assume)
* Identify when LLMs help vs. hinder

***

**Q12: How do players perceive LLM-generated content?**

**Why it matters:** If players distrust or dislike LLM content, it doesn't matter if it's technically good.

**Possible concerns:**

* **Uncanny valley:** Content feels "off" (almost but not quite right)
* **Lack of authorship:** Who created this? (no designer signature)
* **Predictability:** LLM patterns become recognizable (boring)
* **Errors:** When LLM makes mistake, breaks immersion

**Possible benefits:**

* **Novelty:** Fresh content, not repetitive
* **Personalization:** Adapts to player interests
* **Responsiveness:** Reacts to unexpected actions

**Research needed:**

* Player perception studies (what feels good/bad?)
* Compare LLM vs. human-authored content (can players tell?)
* Understand acceptable failure rates (how many LLM errors ruin experience?)

***

**Q13: What new design patterns do LLMs enable?**

**Why it matters:** LLMs aren't just better tools for old designs—they might enable NEW designs.

**Speculative possibilities:**

* **Infinite content games:** Procedural narrative that feels authored
* **Truly adaptive NPCs:** Characters that remember and respond to player history
* **Natural language gameplay:** No UI, just conversation
* **Personalized difficulty:** Adapts to individual player skill/preference in real-time

**But also new problems:**

* **Homogenization:** All LLM games feel similar?
* **Loss of designer vision:** No clear authorial voice?
* **Dependency:** Games break if LLM service unavailable?

**Research needed:**

* Experimental game designs (prototype and test)
* Identify what works (emergent best practices)
* Understand limitations (what SHOULDN'T we do with LLMs?)

***

## Area 5: Emergent Complexity and Load Creep

### The Emergence Problem

**Simple systems can create complex behavior.**

* Good: Depth from simple rules (Go, Conway's Game of Life)
* Bad: Overwhelming emergent complexity (Dwarf Fortress cascades)

**Question: When is emergence valuable, and when is it overwhelming?**

***

### Open Questions

**Q14: How do we design for beneficial emergence without overwhelming players?**

**Why it matters:** Want depth, but not incomprehensibility.

**Possible approaches:**

* **Bounded emergence:** Limit interactions (only some things combine)
* **Transparent causality:** Can trace effects back to causes
* **Graduated revelation:** Emergence appears gradually, not all at once
* **Failure safeguards:** Emergent disasters are recoverable

**Challenges:**

* Emergence is by definition unpredictable
* What's "beneficial" varies by player (Explorers love mess, Achievers want control)
* Hard to test (emergence appears over time, in specific contexts)

**Research needed:**

* Case studies (which games handle emergence well?)
* Player preference mapping (who likes/dislikes emergent complexity?)
* Design patterns (how to enable emergence safely?)

***

**Q15: How do we prevent load creep over game lifecycle?**

**Why it matters:** Games get more complex over time (patches, expansions, power creep).

**Observed patterns:**

* **Feature accretion:** Each update adds more
* **Power creep:** New options must be stronger (to be appealing)
* **Legacy burden:** Can't remove old content (players invested)
* **Meta complexity:** Game-about-game knowledge (builds, tier lists)

**Possible solutions:**

* **Rotation:** Remove old content periodically (Magic sets rotate)
* **Simplification passes:** Prune unused/redundant features
* **Parallel complexity:** New content doesn't interact with old (separate modes)
* **Hard resets:** Sequels or seasons (start fresh)

**Challenges:**

* Player investment (don't want to lose progress/knowledge)
* Live service economics (need new content to sell)
* Community resistance (people like complexity)

**Research needed:**

* Analyze successful long-term games (what keeps load manageable?)
* Player retention studies (do simplifications help or hurt?)
* Economic modeling (sustainable complexity growth?)

***

## Area 6: Social and Cultural Dimensions

### Beyond Individual Cognition

**Most cognitive load research focuses on INDIVIDUAL players.**

* But games are social (multiplayer, communities, shared knowledge)
* And cultural (conventions, norms, expectations vary)

***

### Open Questions

**Q16: How does cognitive load distribute across communities?**

**Why it matters:** Players don't learn alone—communities share knowledge.

**Observations:**

* **Wikis:** Community-built references (offload memory to group)
* **Meta-game:** Collective understanding (build guides, tier lists)
* **Teaching:** Experienced players onboard newbies
* **Memes:** Shared knowledge compressed into culture (jokes, terms)

**Questions:**

* Does community knowledge REDUCE individual load? (just look it up)
* Or INCREASE expectation? (must know the meta to play)
* What's the optimal community-individual load split?

**Research needed:**

* Ethnographic studies (how do communities share knowledge?)
* New player experience (with vs. without community support)
* Social cognitive load (coordination, communication, reputation)

***

**Q17: How do cultural differences affect cognitive load?**

**Why it matters:** Games are global. Do load preferences/tolerances vary by culture?

**Hypotheses:**

* **Language:** Non-native speakers have higher text load
* **Game culture:** Regions with complex game history tolerate more (Japan vs. US?)
* **Education systems:** Different math/logic training affects calculation load
* **Social norms:** Collectivist cultures prefer distributed load (cooperation)?

**Current state:** Mostly unknown. Anecdotal observations, little rigorous study.

**Research needed:**

* Cross-cultural playtesting (same game, different cultures)
* Genre preference analysis (what's popular where, and why?)
* Localization studies (does translated game have same load profile?)

***

**Q18: How does age affect cognitive load tolerance?**

**Why it matters:** Children, adults, and elderly process differently.

**Observations:**

* **Children:** Lower working memory, but higher tolerance for repetition
* **Adults:** Peak cognitive capacity, but less free time (busy)
* **Elderly:** Slower processing, but more strategic thinking (experience)

**Questions:**

* Should games targeting different ages have different load profiles?
* Can games be age-adaptive? (same core, different complexity)
* What about games played across generations? (families, grandparents + kids)

**Research needed:**

* Age-comparative studies (same game, different age groups)
* Lifespan cognitive gaming (how do preferences change over life?)
* Intergenerational play (how to accommodate different capacities?)

***

## Area 7: Methodological Challenges

### How Do We Study This?

**Cognitive load in games is hard to research because:**

**1. Ecological Validity**

* Lab studies (controlled) ≠ real play (messy, social, long-term)
* Short sessions ≠ long campaigns
* Solo play ≠ multiplayer dynamics

**2. Individual Differences**

* High variance between players
* Hard to generalize (what's true for Achievers ≠ Socializers)
* Expertise effects (novices ≠ experts)

**3. Complexity**

* Games have many interacting systems
* Hard to isolate variables (is load from X or Y?)
* Emergent properties (sum > parts)

**4. Ethics**

* Can't push players to cognitive overload (harm)
* Informed consent (but explaining study changes behavior)
* Data privacy (tracking player behavior)

***

### Open Questions

**Q19: What are best practices for cognitive load research in games?**

**Possible approaches:**

* **Mixed methods:** Combine quantitative (metrics) + qualitative (interviews)
* **Longitudinal:** Track over time, not just one session
* **Naturalistic:** Study real play, not just lab
* **Participatory:** Involve players in research design

**Research needed:**

* Methodological comparisons (which approaches yield valid results?)
* Replication studies (do findings hold across contexts?)
* Meta-analysis (synthesize existing research)

***

**Q20: How do we balance scientific rigor with practical design?**

**Why it matters:** Designers need answers NOW. Research takes years.

**Tension:**

* **Science:** Needs control, replication, peer review (slow)
* **Design:** Needs iteration, flexibility, intuition (fast)

**Possible bridges:**

* **Design-based research:** Research THROUGH design (iterate and document)
* **Rapid prototyping:** Test early, learn fast
* **Community science:** Leverage player data (with consent)
* **Practitioner-researcher collaboration:** Designers + academics work together

**Research needed:**

* Case studies of successful design-research partnerships
* Methods for rapid empirical feedback (not full academic studies)
* Ethical frameworks for player data use

***

## Directions for Future Work

### High-Priority Research

**If you're a researcher or designer looking to contribute, these areas need work:**

**1. Measurement Tools**

* Develop reliable cognitive load scales for games
* Validate across genres and player types
* Make tools accessible to designers (not just academics)

**2. LLM Integration**

* Systematic testing of LLM capabilities/limitations in games
* Best practices for LLM-assisted design
* Player perception studies (do they like LLM content?)

**3. Accessibility**

* Partner with disabled players (co-design)
* Develop cognitive accessibility guidelines
* Test interventions (do assistive tools work?)

**4. Cultural and Social Dimensions**

* Cross-cultural load studies
* Community knowledge distribution analysis
* Age-related cognitive load research

**5. Longitudinal Studies**

* Track load over learning curves (weeks/months)
* Understand retention and plateau effects
* Identify optimal load trajectories

***

### Theoretical Gaps

**Areas needing deeper conceptual work:**

**1. Flow and Load**

* Formal model linking cognitive load to flow states
* Understand non-flow enjoyment (when is under-stimulation good?)

**2. Emergence**

* Theory of beneficial vs. overwhelming emergence
* Design patterns for managing emergent complexity

**3. Load Distribution**

* Formal models of distributed cognition in games
* Optimal strategies for asymmetric load

**4. Balance and Accessibility**

* Integrate cognitive load into balance theory
* Understand perceivable vs. actual balance

***

### Practical Applications

**Tools designers need:**

**1. Load Estimation Tools**

* Software to predict cognitive load from game features
* Heuristics for quick assessment

**2. Playtesting Protocols**

* Standardized methods for measuring load
* Guidelines for interpreting results

**3. Design Pattern Library**

* Catalog of load management techniques
* Searchable by context (genre, platform, audience)

**4. Case Study Database**

* Examples of successful load-appropriate designs
* Failures to learn from (what NOT to do)

***

## Conclusion: The Research Frontier

**What we know:**

* Cognitive load is multi-dimensional (simultaneity, decision, memory, tracking, calculation, pattern, social)
* Different experiences require different load profiles
* Load can be supported (tools, UI, automation) or removed (simplification, offloading)
* Player types have different load preferences
* Load must match intended experience

**What we don't know yet:**

* How to reliably measure cognitive load in games
* Optimal load curves for different aesthetics
* How to design for cognitive accessibility without compromising depth
* What LLMs can/can't do reliably
* How to prevent load creep in long-term games
* Cultural and age-related differences in load tolerance
* How community knowledge affects individual cognitive load

**The opportunity:**

This field is YOUNG. Most questions are open. Every designer and researcher can contribute.

**By studying cognitive load systematically:**

* We create more accessible games (inclusive design)
* We understand player experience better (why some games work)
* We enable new design possibilities (LLMs, adaptive systems)
* We improve our craft (intentional, evidence-based design)

**The questions in this chapter aren't obstacles—they're invitations.**

What will you explore?
