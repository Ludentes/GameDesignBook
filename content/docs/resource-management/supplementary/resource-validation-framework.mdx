---
title: "Resource Design Validation Framework"
---
# Resource Design Validation Framework
## A Playtesting Guide for Designers

**Purpose:** This framework helps you test whether your resource design decisions actually create the experiences you intended. It provides concrete metrics, observation protocols, and diagnostic tools to validate resources through playtesting.

**Who this is for:** Designers who have made resource design decisions (following Chapter 2's framework) and need to validate those decisions before full production.

**What you'll get:** Specific tests, metrics, and questions that reveal whether your resources are working as intended.

---

## Part 1: Pre-Playtest Preparation

Before testing, document your design intentions clearly. This creates the baseline against which you'll measure reality.

### Document Your Resource Hypothesis

For each resource in your game, complete this template:

**Resource Name:** _________________

**Function (Limiter/Currency/Tracker/Meta-Resource):** _________________

**Behavior Pattern (Consumable/Buffer/Accumulation/Composition/Capacity):** _________________

**Intended Aesthetic Goal:** _________________
- What experience should this resource create?
- What should players FEEL when interacting with this resource?

**Intended Strategic Pattern:** _________________
- What decisions should this resource create?
- What should players THINK ABOUT when using this resource?

**Scarcity Level Hypothesis:** _________________
- Extreme Scarcity / Strategic Scarcity / Comfortable Abundance / Extreme Abundance
- Why this level serves the aesthetic?

**Recovery Pattern Hypothesis (if applicable):** _________________
- None / Slow / Moderate / Fast
- Expected pacing outcome: Attrition / Episodic / Wave / Continuous / Punctuated

**Expected Player Behavior:** _________________
- What should players DO with this resource?
- What trade-offs should they make?

**Success Criteria:** _________________
- How will you know this resource is working correctly?
- What observable behaviors indicate success?

**Example - Completed Template:**

**Resource Name:** Investigation Points

**Function:** Currency

**Behavior Pattern:** Consumable with moderate recovery

**Intended Aesthetic Goal:** Discovery (finding clues) + Challenge (prioritizing which leads to pursue)

**Intended Strategic Pattern:** 
- Players choose which leads to investigate deeply
- Trade-off: Pursue this witness thoroughly vs. spread points across multiple leads
- Feel clever when points spent well reveal critical connections

**Scarcity Level Hypothesis:** Strategic scarcity
- Players have enough to investigate 2-3 leads deeply per scene
- Cannot investigate everything exhaustively
- Forces prioritization decisions

**Recovery Pattern Hypothesis:** Moderate (per scene)
- Recover 5 points between scenes
- Creates episodic pacing (fresh investigation capacity per scene)

**Expected Player Behavior:**
- Discuss which leads seem most promising
- Debate whether to go deep on one lead or shallow on many
- Occasionally regret spending points on dead ends
- Feel satisfaction when chosen lead pays off

**Success Criteria:**
- Players debate point spending for 20-30 seconds before choosing
- Players verbalize trade-offs ("If we spend here, we can't spend there")
- Players express satisfaction when good spending reveals clues
- Players occasionally say "I wish we'd spent points differently" (mild regret, not frustration)

---

## Part 2: Observation Protocol During Playtesting

### General Observation Guidelines

**DO:**
- ‚úÖ Watch what players actually do (behavior > stated intentions)
- ‚úÖ Note emotional responses (frustration, excitement, confusion, satisfaction)
- ‚úÖ Record time spent on decisions (too fast = obvious, too slow = analysis paralysis)
- ‚úÖ Listen for spontaneous comments ("I wish I had more X", "Why am I tracking Y?")
- ‚úÖ Track resource state over time (abundance curves, depletion patterns)

**DON'T:**
- ‚ùå Interrupt to explain rules (note confusion, fix after session)
- ‚ùå Ask leading questions ("Don't you think this resource is scarce?")
- ‚ùå Defend design choices during play (you're testing, not justifying)
- ‚ùå Only watch optimal play (watch mistakes‚Äîthey're informative)

### Resource-Specific Observation Checklist

**For ALL Resources:**

‚ñ° **Visibility:** Do players notice this resource exists?
- Failure signal: Players ignore resource entirely
- Success signal: Players reference resource when making decisions

‚ñ° **Understanding:** Do players understand what this resource does?
- Failure signal: Players ask "What is [resource] for?" multiple times
- Success signal: Players explain resource function to each other correctly

‚ñ° **Tracking Load:** Can players track current resource state?
- Failure signal: Players constantly ask "How much [resource] do I have?"
- Success signal: Players know approximate state without checking

‚ñ° **Decision Creation:** Does this resource create decisions?
- Failure signal: Players never discuss this resource when choosing actions
- Success signal: Players explicitly reference resource when evaluating options

**For LIMITERS Specifically:**

‚ñ° **Scarcity Perception:** Do players feel the constraint?
- Too scarce: Players express frustration, feel blocked
- Strategic scarcity: Players express tension, make trade-offs
- Too abundant: Players never mention running out

‚ñ° **Recovery Understanding:** Do players know when/how resource recovers?
- Failure signal: Players surprised when resource doesn't recover
- Success signal: Players plan around recovery timing

‚ñ° **Pacing Effect:** Does recovery pattern create intended pacing?
- Slow recovery: Do players play conservatively? Express attrition pressure?
- Fast recovery: Do players play aggressively? Reset between encounters?
- No recovery: Do players express high stakes? Conservative with every use?

**Observation Prompt Questions (ask AFTER play, not during):**
- "What resources felt scarce? What felt abundant?"
- "Which resources did you think about most during play?"
- "Were there any resources you forgot about or ignored?"
- "When did you feel pressure? When did you feel safe?"

**For CURRENCIES Specifically:**

‚ñ° **Spending Decisions:** Are players making meaningful trade-offs?
- Failure signal: Players always buy same thing (dominant strategy)
- Success signal: Players debate multiple roughly-equal options

‚ñ° **Opportunity Cost:** Do players verbalize "can't afford both"?
- Failure signal: Players can buy everything they want
- Success signal: Players discuss priorities, compromise

‚ñ° **Value Understanding:** Do players know what's worth spending on?
- Failure signal: Players spend randomly or ask "Is this worth it?"
- Success signal: Players compare value of options

**Observation Prompt Questions:**
- "What did you spend [currency] on? Why those choices?"
- "Were there things you wanted but couldn't afford?"
- "Did any purchases feel like mistakes? Which felt good?"
- "If you could replay, would you spend differently?"

**For TRACKERS Specifically:**

‚ñ° **Progress Visibility:** Can players see advancement?
- Failure signal: Players don't know how much they've completed
- Success signal: Players reference progress ("50% explored")

‚ñ° **Motivation:** Does tracking create goals?
- Failure signal: Players don't care about completion
- Success signal: Players express desire to complete ("Only 3 more!")

‚ñ° **Information Value:** Does tracking provide useful information?
- Failure signal: Players never check tracker
- Success signal: Players consult tracker to plan next actions

**Observation Prompt Questions:**
- "Did you care about completing [collection/exploration]?"
- "How did you track what you'd found vs. what was left?"
- "Did completion percentage affect your decisions?"

**For COMPOSITION Resources Specifically:**

‚ñ° **Synergy Awareness:** Do players recognize combinations?
- Failure signal: Players treat all pieces equally
- Success signal: Players discuss "this works with that"

‚ñ° **Curation Behavior:** Do players sometimes decline additions?
- Failure signal: Players always take more resources
- Success signal: Players say "No, that doesn't fit my build"

‚ñ° **Build Planning:** Do players think ahead about composition?
- Failure signal: Players grab whatever's available
- Success signal: Players reference long-term build goals

**Observation Prompt Questions:**
- "What was your strategy for [deck/loadout/team]?"
- "Did you ever skip something because it didn't fit?"
- "What synergies did you discover?"
- "Would you build differently next time?"

---

## Part 3: Quantitative Metrics

Collect these numbers during playtesting to validate resource design.

### Metric 1: Resource State Over Time

**What to track:** Resource quantity at regular intervals (every 5 minutes or per encounter)

**How to collect:**
- Snapshot resource values at consistent checkpoints
- Graph over session time
- Look for patterns: Linear? Cyclical? Random? Trending?

**What it reveals:**

**Abundance Curve - Rising:**
- Resource accumulates faster than spent
- Suggests too abundant OR not enough spending opportunities
- Diagnostic: Is this intentional progression, or broken economy?

**Abundance Curve - Falling:**
- Resource depletes faster than recovered
- Suggests too scarce OR recovery too slow
- Diagnostic: Is this intentional attrition, or death spiral?

**Abundance Curve - Cyclical:**
- Resource goes up and down in regular pattern
- Suggests episodic or wave pacing
- Diagnostic: Are cycles appropriate length for aesthetic?

**Abundance Curve - Flat/Stable:**
- Resource stays around same level
- Suggests balanced economy OR unused resource
- Diagnostic: Are players making decisions, or just not engaging?

**Example Target Curves:**

**Challenge Aesthetic (Strategic Scarcity):**
- Should see: Stable with occasional dips (recovery balances spending)
- Red flag: Constantly rising (too abundant) or constantly falling (too scarce)

**Tension Aesthetic (Attrition):**
- Should see: Gradual decline over session (pressure builds)
- Red flag: Stable or rising (no attrition pressure)

**Progression Aesthetic (Accumulation):**
- Should see: Steady rise over time (power curve)
- Red flag: Flat or declining (no progression feeling)

### Metric 2: Decision Time per Resource Spending

**What to track:** How long do players spend deciding to use a resource?

**How to collect:**
- Time from "considering spending resource" to "decision made"
- Average across multiple decisions
- Compare across different resources

**What it reveals:**

**less than 5 seconds:**
- Obvious decision (might be false choice)
- OR simple decision (appropriate for fast-paced game)
- Diagnostic: Is this resource creating meaningful choices?

**5-30 seconds:**
- Strategic decision (evaluating trade-offs)
- Healthy deliberation for most games
- Suggests resource is creating meaningful choices

**30-60 seconds:**
- Complex decision (multiple factors)
- Appropriate for deep strategy games
- Risk: Might be analysis paralysis for casual games

**>60 seconds:**
- Analysis paralysis (too complex or unclear)
- Players can't evaluate options
- Diagnostic: Simplify resource system or improve information

**Example Analysis:**

Game with Challenge aesthetic, midcore audience:
- Investigation Points: Average 25 seconds per spending decision ‚úÖ Good
- Gold: Average 3 seconds per purchase ‚ö†Ô∏è Too fast‚Äîdominant strategies?
- HP healing: Average 90 seconds per decision ‚ùå Too slow‚Äîunclear optimal play?

**Action:** Investigate why gold decisions are instant (probably one option always best) and why healing decisions take so long (probably unclear recovery mechanics).

### Metric 3: Resource Depletion Events

**What to track:** How often do players fully deplete each resource?

**How to collect:**
- Count instances where resource reaches zero
- Track what happens next (death? inconvenience? nothing?)
- Note player emotional response

**What it reveals:**

**Never depletes:**
- Resource is too abundant
- OR players are over-conserving (hoarding)
- Diagnostic: Is resource actually constraining? Or just tracked number?

**Depletes occasionally (10-20% of encounters):**
- Strategic scarcity working well
- Creates tension without constant frustration
- Appropriate for most Challenge/Tension aesthetics

**Depletes frequently (50%+ of encounters):**
- Too scarce OR recovery too slow
- Risk of frustration, death spirals
- Appropriate only for extreme difficulty or horror

**Depletion has no consequence:**
- Resource is pointless
- Players should feel depletion impact
- Diagnostic: Why track this resource at all?

**Example Analysis:**

Horror game testing:
- Ammunition: Depletes 60% of encounters ‚úÖ Creates intended dread
- Health: Depletes 5% of encounters ‚ö†Ô∏è Might be too safe for horror
- Flashlight battery: Never depletes ‚ùå Not creating constraint‚Äîremove or reduce capacity

### Metric 4: Resource Interaction Frequency

**What to track:** How often do players engage with each resource?

**How to collect:**
- Count resource acquisition events
- Count resource spending events
- Count player-initiated resource checks (looking at current amount)
- Calculate interactions per minute of play

**What it reveals:**

**High frequency (multiple times per minute):**
- Micro-loop resource (appropriate for action games)
- OR resource is creating constant decisions (good or bad?)
- Diagnostic: Is this high engagement intended, or cognitive overload?

**Medium frequency (every few minutes):**
- Meso-loop resource (appropriate for tactical decisions)
- Regular engagement without overwhelming
- Sweet spot for most strategic resources

**Low frequency (every 10+ minutes):**
- Macro/meta-loop resource (appropriate for long-term progression)
- OR players are ignoring resource
- Diagnostic: Is low frequency intentional, or is resource invisible?

**Never interacted:**
- Resource is invisible to players
- Complete failure‚Äîremove or redesign
- Players don't understand it exists or matters

**Example Analysis:**

RPG testing (60-minute session):
- HP: Checked 45 times (0.75/min) ‚úÖ Appropriate for buffer resource
- Gold: Spent 8 times (0.13/min) ‚úÖ Appropriate for currency
- Skill points: Spent 2 times (0.03/min) ‚úÖ Appropriate for meta-resource
- Crafting materials: Never interacted ‚ùå Players don't understand crafting system

### Metric 5: Multiple Demand Distribution

**What to track:** For currencies, what percentage of spending goes to each option?

**How to collect:**
- Record every spending decision and what was purchased
- Calculate percentage distribution across all options
- Compare to ideal distribution for meaningful choice

**What it reveals:**

**One option: 80%+ of spending:**
- Dominant strategy (false choice)
- Players figured out "best" use
- Other options are trap choices
- Diagnostic: Balance options or remove inferior ones

**One option: 50-70% of spending:**
- Strong preference (might be okay if other options are situational)
- Watch for player types‚Äîmaybe viable for different builds?
- Diagnostic: Are other options viable niches, or just worse?

**Roughly even distribution (20-40% each across 3-5 options):**
- Healthy opportunity cost
- Multiple viable strategies
- Success‚Äîmeaningful choices

**All options used rarely (less than 10% each):**
- Players don't know what to buy
- Too many options (choice paralysis)
- Unclear value propositions
- Diagnostic: Reduce options or improve clarity

**Example Analysis:**

Strategy game testing‚Äîgold spending distribution:
- Military units: 65% ‚ö†Ô∏è Dominant strategy emerging
- Economic buildings: 20% ‚úÖ Situational but viable
- Technology: 12% ‚ö†Ô∏è Might be undervalued
- Diplomacy: 3% ‚ùå Clearly inferior‚Äîbuff or remove

---

## Part 4: Qualitative Assessment

Numbers tell you WHAT is happening. Player feedback tells you WHY.

### Post-Session Interview Questions

**About Resource Awareness:**
1. "Which resources did you think about most during play?"
2. "Were there any resources you forgot existed?"
3. "Which resources felt important? Which felt like busywork?"

**Expected responses for working resources:**
- Players name the resource unprompted
- Players describe resource function accurately
- Players connect resource to their strategic decisions

**Red flags:**
- "Wait, we had [resource]? I didn't notice."
- "I don't know what [resource] does."
- "I just ignored [resource]."

**About Scarcity and Abundance:**
4. "Which resources felt scarce? Which felt plentiful?"
5. "Did you ever feel blocked by lack of resources?"
6. "Did you ever have so much of a resource you stopped caring about it?"

**Expected responses for strategic scarcity:**
- "I wished I had more [resource] sometimes"
- "I had to choose carefully where to spend [resource]"
- "Resources felt tight but not frustrating"

**Red flags:**
- "I never had enough [resource] to do anything" (too scarce)
- "I had way more [resource] than I needed" (too abundant)
- "I stopped tracking [resource] because it didn't matter" (broken economy)

**About Decisions and Trade-offs:**
7. "What were the hardest decisions you made?"
8. "Were there times you wanted to do multiple things but couldn't?"
9. "Did any decisions feel obvious? Did any feel impossible to evaluate?"

**Expected responses for working resources:**
- Players describe resource trade-offs as hard decisions
- Players mention weighing multiple options
- Players express satisfaction when choices paid off

**Red flags:**
- "I just always did [X], it was obviously best" (false choice)
- "I had no idea what to choose, so I guessed" (unclear value)
- "I never had to choose, I could do everything" (too abundant)

**About Emotional Experience:**
10. "When did you feel tense? When did you feel safe?"
11. "Were there moments of satisfaction? Frustration?"
12. "Did the game feel stressful, relaxing, or something else?"

**Expected responses (match to aesthetic):**
- Challenge aesthetic: "Tense but fair", "Satisfying when I figured it out"
- Tension aesthetic: "Stressful in a good way", "Never felt completely safe"
- Submission aesthetic: "Relaxing", "Could just zone out"
- Discovery aesthetic: "Excited to find things", "Satisfying to uncover secrets"

**Red flags (aesthetic mismatch):**
- Challenge game: "Frustrating and unfair" (too scarce)
- Tension game: "Relaxing and easy" (too abundant)
- Submission game: "Stressful and demanding" (too scarce)

**About Pacing and Recovery:**
13. "Did the game feel like it had a rhythm? What was it like?"
14. "Were there moments of relief? Or was it constant pressure?"
15. "Did resources recover at the right speed?"

**Expected responses (match to pacing pattern):**
- Attrition pacing: "Pressure built over time", "Felt more difficult as we went"
- Episodic pacing: "Each fight was fresh", "Reset between encounters"
- Wave pacing: "Build up and release cycle", "Intense then calm"

**Red flags:**
- "Resources never recovered" (when you wanted episodic)
- "No sense of progression" (when you wanted attrition)
- "Too much downtime" (recovery too frequent)

### Observing Player Language

**Listen for these spontaneous phrases:**

**Resource is working well:**
- "I wish I could do both" (opportunity cost)
- "This is a tough call" (meaningful decision)
- "I'm saving this for later" (strategic conservation)
- "Yes! That worked!" (satisfaction from good spending)
- "I need to be more careful with [resource]" (scarcity awareness)

**Resource is too scarce:**
- "I can't do anything" (blocked by scarcity)
- "This is impossible" (frustration)
- "I'm just stuck" (death spiral)
- "I can't afford to play" (scarcity preventing engagement)

**Resource is too abundant:**
- "I have way too much [resource]" (broken economy)
- "I stopped caring about [resource]" (abundance removed stakes)
- "I can do everything" (no opportunity cost)
- "Why am I even tracking this?" (pointless resource)

**Resource is confusing:**
- "What does [resource] do again?" (unclear function)
- "I don't know if this is good" (unclear value)
- "How much do I have?" (poor visibility)
- "I forgot about [resource]" (invisible resource)

**Resource creates wrong emotional response:**
- "This is tedious" (tracking burden for Submission game)
- "This is boring" (no meaningful decisions in Challenge game)
- "This stresses me out" (scarcity in Submission game)
- "This is too easy" (abundance in Challenge game)

---

## Part 5: Diagnostic Decision Trees

When playtesting reveals problems, use these trees to diagnose root causes.

### Problem: Players Ignore a Resource

**Question 1: Do players know the resource exists?**
- NO ‚Üí Visibility problem
  - Solution: Improve UI, add tutorial, make acquisition more obvious
- YES ‚Üí Continue to Question 2

**Question 2: Do players understand what the resource does?**
- NO ‚Üí Communication problem
  - Solution: Clearer tooltips, better naming, show function through use
- YES ‚Üí Continue to Question 3

**Question 3: Does using the resource create meaningful outcomes?**
- NO ‚Üí Function problem
  - Solution: Resource doesn't affect gameplay‚Äîremove or redesign
- YES ‚Üí Continue to Question 4

**Question 4: Is the resource worth the cognitive overhead?**
- NO ‚Üí Complexity problem
  - Solution: Resource creates trivial decisions‚Äîsimplify or remove
- YES ‚Üí Design working, but players haven't learned it yet‚Äîgive more time

### Problem: Players Run Out of Resource Constantly

**Question 1: Is this intentional (Tension/Horror aesthetic)?**
- YES ‚Üí Working as designed IF players express appropriate tension (not frustration)
  - Check: Are players engaged or frustrated?
  - Frustrated ‚Üí Too scarce even for intended aesthetic
  - Engaged ‚Üí Scarcity working correctly
- NO ‚Üí Continue to Question 2

**Question 2: Are players spending inefficiently?**
- YES ‚Üí Education problem
  - Solution: Better feedback on value, clearer trade-offs, tutorial
- NO ‚Üí Continue to Question 3

**Question 3: Is resource acquisition clear and accessible?**
- NO ‚Üí Access problem
  - Solution: Make acquisition more obvious or more frequent
- YES ‚Üí Continue to Question 4

**Question 4: Is recovery speed appropriate for pacing?**
- NO ‚Üí Recovery problem
  - Solution: Increase recovery speed or frequency
- YES ‚Üí Resource is genuinely too scarce‚Äîincrease availability

### Problem: Players Never Run Out of Resource

**Question 1: Is this intentional (Submission/Narrative aesthetic)?**
- YES ‚Üí Working as designed IF resource isn't creating decision overhead
  - Check: Do players care about tracking this resource?
  - Don't care ‚Üí Remove resource (not adding value)
  - Care ‚Üí Abundance working correctly
- NO ‚Üí Continue to Question 2

**Question 2: Are players over-conserving (hoarding)?**
- YES ‚Üí Psychological problem
  - Solution: Faster recovery (reduces hoarding), forced spending (expiring resources), or clear signaling (show when resource not needed)
- NO ‚Üí Continue to Question 3

**Question 3: Are there enough valuable uses for the resource?**
- NO ‚Üí Demand problem
  - Solution: Add more spending opportunities or increase costs
- YES ‚Üí Continue to Question 4

**Question 4: Is acquisition too generous?**
- YES ‚Üí Supply problem
  - Solution: Reduce acquisition rate or amount
- NO ‚Üí Players aren't engaging with spending mechanics‚Äîsee "Players Ignore Resource" tree

### Problem: Resource Decisions Feel Obvious

**Question 1: Is there a dominant strategy?**
- YES ‚Üí Balance problem
  - Solution: Buff weak options or nerf strong option‚Äîensure roughly equal value
- NO ‚Üí Continue to Question 2

**Question 2: Are trade-offs visible before decision?**
- NO ‚Üí Information problem
  - Solution: Show opportunity costs, compare options, clarify value
- YES ‚Üí Continue to Question 3

**Question 3: Do different player types value options differently?**
- YES ‚Üí Might be okay‚Äîworking for different builds
  - Check: Do players build different strategies around different options?
  - Different strategies ‚Üí Healthy diversity
  - Everyone picks same option ‚Üí Balance problem (return to Q1)
- NO ‚Üí Continue to Question 4

**Question 4: Is resource so abundant that spending doesn't matter?**
- YES ‚Üí Scarcity problem
  - Solution: Reduce resource abundance or increase costs
- NO ‚Üí Resource might actually be creating meaningful choice‚Äîvalidate with more testing

### Problem: Resource Decisions Take Too Long

**Question 1: Is value of options unclear?**
- YES ‚Üí Clarity problem
  - Solution: Better tooltips, clearer feedback, show expected outcomes
- NO ‚Üí Continue to Question 2

**Question 2: Are there too many options?**
- YES ‚Üí Complexity problem
  - Solution: Reduce options, categorize choices, staged decisions
- NO ‚Üí Continue to Question 3

**Question 3: Do options require complex calculations?**
- YES ‚Üí Cognitive load problem
  - Solution: Simplify math, show calculated values, reduce variables
- NO ‚Üí Continue to Question 4

**Question 4: Is this player type appropriate for complexity?**
- NO ‚Üí Audience mismatch
  - Solution: Simplify for casual, OR accept complexity for hardcore audience
- YES ‚Üí Might be appropriate complexity for deep strategy‚Äîvalidate if players enjoy depth

---

## Part 6: Resource-Specific Validation Tests

### Test 1: The Removal Test (Is this resource necessary?)

**How to run:**
1. Remove the resource entirely from one playtest session
2. See if players notice or care
3. Check if game still functions

**What it reveals:**
- Players don't notice ‚Üí Resource was unnecessary, remove permanently
- Players notice but game works ‚Üí Resource adds flavor not function, consider removing
- Game breaks without resource ‚Üí Resource is essential, keep and improve
- Players specifically miss the resource ‚Üí Resource creates valued experience, keep

**Example:**
Testing crafting materials in RPG:
- Removed materials from session
- Players defeated enemies, got gold directly instead
- No player mentioned missing crafting
- Diagnostic: Crafting materials unnecessary middleman, simplify to direct gold

### Test 2: The Abundance Test (Would infinite resources break the game?)

**How to run:**
1. Give players unlimited quantity of one resource
2. Observe what they do with infinite resource
3. Check if game becomes trivial or still engaging

**What it reveals:**
- Game becomes trivial ‚Üí Resource scarcity is essential to challenge, keep scarce
- Players still make interesting decisions ‚Üí Resource amount doesn't matter much, remove or rethink
- Players use resource differently ‚Üí Reveals true value‚Äîmight be mis-scarcity'd
- Players ignore infinite resource ‚Üí Resource was never engaging, remove

**Example:**
Testing HP in action game:
- Gave players infinite HP (invincibility)
- Game became trivial, players stopped caring about enemy attacks
- Diagnostic: HP scarcity creates the core challenge, keep scarce

**Example 2:**
Testing quest markers in open world:
- Gave players all map markers revealed
- Players still explored organically, just more efficiently
- Game still engaging, exploration still fun
- Diagnostic: Discovery isn't about hidden markers, it's about world content‚Äîreveal markers

### Test 3: The Forced Choice Test (Are trade-offs real?)

**How to run:**
1. Present players with binary choice requiring resource spending
2. Option A and Option B should be roughly equal value
3. Force immediate decision (no more information, no time to optimize)
4. Observe: Do players debate? Express uncertainty? Or choose instantly?

**What it reveals:**
- Players debate (20-40 seconds) ‚Üí Healthy trade-off, options balanced
- Players choose instantly ‚Üí One option obviously better, balance problem
- Players can't decide (60+ seconds) ‚Üí Unclear value, information problem
- Players don't care ‚Üí Resource not valuable, remove or increase stakes

**Example:**
Testing skill point spending:
- Force choice: +10% damage OR +20% defense
- Players debate, discuss build strategies, express uncertainty
- Diagnostic: Healthy trade-off, both options valuable

**Example 2:**
Testing gold spending:
- Force choice: Magic sword (100g) OR Healing potion (100g)
- Players instantly buy sword every time
- Diagnostic: Sword obviously better, potion is trap choice‚Äîbalance or remove

### Test 4: The Regret Test (Do bad choices matter?)

**How to run:**
1. Let players make resource decisions naturally
2. Later, reveal information that their choice was suboptimal
3. Observe emotional response and desire to replay

**What it reveals:**
- Mild regret + desire to try differently ‚Üí Good strategic depth, learning curve
- Intense frustration + anger ‚Üí Consequences too harsh or information too hidden
- No emotional response ‚Üí Choices don't matter enough
- Relief that "wrong" choice still worked ‚Üí Good forgiveness, accessible design

**Example:**
Testing Investigation Points spending:
- Players spend points investigating witness who turns out uninvolved
- Players express "Oh, we should have investigated the butler instead"
- Players want to replay with better strategy
- Diagnostic: Healthy strategic depth, choices matter but aren't punishing

**Example 2:**
Testing irreversible skill tree:
- Players invest in path that becomes useless later
- Players express anger, feel trapped
- No desire to replay (too invested to restart)
- Diagnostic: Consequences too harsh, allow respec or improve signaling

### Test 5: The Tutorial Removal Test (Is resource intuitive?)

**How to run:**
1. Remove all tutorial/explanation for one resource
2. See if players discover function through play
3. Check how long until players understand resource

**What it reveals:**
- Players understand immediately ‚Üí Intuitive design, minimal tutorial needed
- Players understand within 10-15 minutes ‚Üí Discoverable through play, light tutorial okay
- Players confused after 30 minutes ‚Üí Needs explanation, add tutorial
- Players never understand ‚Üí Design unclear, redesign or heavy tutorial

**Example:**
Testing HP bar:
- No tutorial
- Players understand "red bar going down = bad" within seconds
- Diagnostic: Intuitive, no tutorial needed

**Example 2:**
Testing combo system:
- No tutorial
- Players never discover combo mechanics in 60-minute session
- Diagnostic: Not discoverable, needs tutorial or redesign for clarity

### Test 6: The Recovery Speed Test (Does pacing match aesthetic?)

**How to run:**
1. Playtest session with current recovery speed
2. Second playtest with 2x faster recovery
3. Third playtest with 2x slower recovery
4. Compare player behavior and emotional experience

**What it reveals:**
- Current speed creates intended experience ‚Üí Keep as is
- Faster creates intended experience ‚Üí Recovery too slow, increase
- Slower creates intended experience ‚Üí Recovery too fast, decrease
- None create intended experience ‚Üí Wrong resource type, not just wrong speed

**Example:**
Testing HP recovery in action game:
- Current: Recover 50% HP between encounters (episodic)
- 2x faster: Full HP instantly, players play very aggressively
- 2x slower: 25% HP recovery, players too cautious
- Diagnostic: Current speed creates intended balanced-aggression, keep 50%

**Example 2:**
Testing spell slots in RPG:
- Current: Recover per long rest (8 hours), creates attrition
- 2x faster: Recover per short rest (1 hour), players spam spells
- 2x slower: Recover once per 2 days, players hoard spells
- Diagnostic: Current speed creates intended attrition, keep long rest

---

## Part 7: Composite Validation‚ÄîTesting Multiple Resources Together

Individual resource tests are necessary but insufficient. Resources interact, creating emergent complexity.

### Test 7: The Cognitive Load Test (Can players track everything?)

**How to run:**
1. During playtest, periodically ask players "What resources do you have?"
2. See if they can recall without checking
3. Count how often players check resource state during decisions
4. Note which resources are forgotten

**What it reveals:**
- Players recall all resources ‚Üí Cognitive load appropriate
- Players recall 2-3 but forget others ‚Üí Too many resources, or some are invisible
- Players constantly check UI ‚Üí Tracking load too high
- Players make decisions without checking ‚Üí Resource state not important (bad) OR intuitive (good)

**Benchmark guidelines:**
- Casual games: Players should track 2-4 resources comfortably
- Midcore games: 3-5 resources manageable
- Hardcore games: 4-6+ resources possible

**Diagnostic:**
- If players forget resources: Remove least-used, or improve visibility
- If players constantly check: Reduce resource count, or improve UI clarity
- If players don't check: Resources might not matter (remove) OR are intuitive (good)

### Test 8: The Decision Stack Test (Do resources compete for attention?)

**How to run:**
1. Identify moments where multiple resources could affect decision
2. Observe which resources players actually consider
3. Track "consideration order"‚Äîwhich resources are checked first, second, third
4. Note which resources are never considered

**What it reveals:**
- Clear priority hierarchy ‚Üí Dominant resource, others might be noise
- All resources considered ‚Üí Good depth, but check for cognitive overload
- Same resources ignored repeatedly ‚Üí Remove those resources
- Different players prioritize differently ‚Üí Healthy diversity OR confusion

**Example:**
Combat decision‚Äîplayer choosing between attack, defend, or ability:
- Player checks HP first ‚Üí Health drives decision (primary concern)
- Player checks enemy HP second ‚Üí Damage calculation (secondary)
- Player never checks mana ‚Üí Mana either abundant OR player forgot it exists
- Diagnostic: HP and damage are important, investigate why mana ignored

### Test 9: The Interaction Test (Do resources combine interestingly?)

**How to run:**
1. Document all resource interaction points (conversions, limits, synergies)
2. Observe if players discover and use interactions
3. Check if interactions create depth or confusion

**What it reveals:**
- Players discover and use interactions ‚Üí Good depth, emergent strategy
- Players never discover interactions ‚Üí Too hidden, add signaling
- Players discover but find confusing ‚Üí Too complex, simplify
- Interactions don't affect decisions ‚Üí Remove interactions, unnecessary complexity

**Example:**
Testing resource conversion (gold ‚Üí HP via potions):
- Players discover conversion immediately
- Players debate "buy potions now or save gold for equipment?"
- Interaction creates meaningful trade-off
- Diagnostic: Good interaction, creates strategic depth

**Example 2:**
Testing resource limiting (energy limits card plays):
- Players frequently forget energy limits
- Players surprised when "out of energy"
- Interaction creates frustration, not strategy
- Diagnostic: Energy limit unclear, improve feedback or remove

### Test 10: The Balance Validation Test (Are resources balanced across session?)

**How to run:**
1. Track all resources from session start to session end
2. Plot resource curves over time
3. Check if any resource becomes dominant or useless
4. Verify intended resource relationships hold

**What it reveals:**
- All resources maintain relevance ‚Üí Good balance
- One resource becomes irrelevant ‚Üí Broken scaling, needs adjustment
- One resource dominates late ‚Üí Progression might be too strong
- Resources diverge unexpectedly ‚Üí Hidden interactions breaking balance

**Example:**
RPG testing across 4-hour session:
- Gold: Starts scarce, becomes abundant (hour 3+)
- HP: Remains consistently relevant
- Mana: Becomes irrelevant (hour 2+, too much regeneration)
- Diagnostic: Gold economy needs late-game sinks, mana regeneration too generous

**Validation questions:**
- "Does each resource matter throughout entire session?"
- "Do resource relationships stay consistent or shift?"
- "Do any resources become trivial or overwhelming?"
- "Is resource progression (if any) intentional and appropriate?"

---

## Part 8: Validation Checklist by Aesthetic

Different aesthetics require different validation approaches. Use these checklists to ensure resources serve intended experiences.

### Challenge Aesthetic Validation

**Core requirement: Resources create meaningful constraints and decisions**

‚ñ° **Scarcity Test:** Do players regularly face "can't do both" situations?
- Should see: Trade-off discussions, priority debates
- Red flag: Players can do everything, no choices

‚ñ° **Decision Quality:** Do players spend 10-30 seconds on resource decisions?
- Should see: Strategic deliberation
- Red flag: Instant decisions (obvious) or 60+ seconds (analysis paralysis)

‚ñ° **Consequence Test:** Do resource mistakes feel fair and educational?
- Should see: "I should have spent differently" (learning)
- Red flag: "How was I supposed to know that?" (unfair) or "Doesn't matter" (no stakes)

‚ñ° **Optimization Space:** Can skilled players use resources more efficiently than novices?
- Should see: Skill differentiation in resource management
- Red flag: Everyone uses resources the same way (no skill expression)

‚ñ° **Balance Validation:** Do multiple resource strategies remain viable?
- Should see: Different players succeed with different approaches
- Red flag: One dominant strategy (false choice)

**Challenge Aesthetic Success Criteria:**
- Players verbalize trade-offs
- Strategic scarcity maintained throughout session
- Mistakes feel educational, not punishing
- Skill affects resource efficiency

### Discovery Aesthetic Validation

**Core requirement: Resources track progress and enable exploration**

‚ñ° **Tracking Clarity:** Do players know what they've found and what's left?
- Should see: Players reference progress ("80% explored")
- Red flag: Players can't track completion status

‚ñ° **Motivation Test:** Does tracking create desire to complete?
- Should see: "Only 3 more to find!" excitement
- Red flag: Players don't care about completion

‚ñ° **Non-Blocking:** Do resources never prevent exploration?
- Should see: Players always able to access new areas/content
- Red flag: Resource scarcity blocks progress (gates content)

‚ñ° **Discovery Excitement:** Do new resource acquisitions feel rewarding?
- Should see: Positive emotional response to finding things
- Red flag: Tracking feels like chore

‚ñ° **Breadcrumb Effectiveness:** Do resources guide toward new discoveries?
- Should see: One discovery leading to next
- Red flag: Players lost, don't know where to explore

**Discovery Aesthetic Success Criteria:**
- Progress tracking is clear and motivating
- Resource acquisition never blocks exploration
- Finding things creates satisfaction
- Resources guide without forcing specific paths

### Mastery Aesthetic Validation

**Core requirement: Resources provide optimization space and depth**

‚ñ° **Complexity Appropriate:** Can hardcore players handle resource complexity?
- Should see: Players discuss optimization strategies
- Red flag: Even experienced players overwhelmed

‚ñ° **Composition Depth:** Do resources combine in interesting ways?
- Should see: Players discovering synergies, planning builds
- Red flag: All resources independent (no interaction depth)

‚ñ° **Optimization Ceiling:** Can players always improve resource efficiency?
- Should see: High-skill players significantly outperform average
- Red flag: No skill differentiation, flat learning curve

‚ñ° **Strategic Diversity:** Do multiple resource strategies succeed?
- Should see: Different viable builds, player creativity
- Red flag: Single optimal strategy (solved game)

‚ñ° **Learning Reward:** Does understanding resources improve performance?
- Should see: Knowledge translating to better outcomes
- Red flag: Understanding resources doesn't help (random) or obvious (trivial)

**Mastery Aesthetic Success Criteria:**
- High complexity acceptable to target audience
- Deep optimization space with no ceiling
- Multiple viable approaches
- System knowledge translates to skill advantage

### Tension Aesthetic Validation

**Core requirement: Resources create pressure and stakes**

‚ñ° **Scarcity Pressure:** Do resources feel constantly threatened?
- Should see: Players expressing tension, careful resource management
- Red flag: Resources abundant, no pressure

‚ñ° **Loss Stakes:** Do resource losses feel significant?
- Should see: Emotional response to depletion
- Red flag: Players don't care about resource loss

‚ñ° **Recovery Anxiety:** Is recovery slow enough to maintain pressure?
- Should see: Attrition pacing, building pressure
- Red flag: Fast recovery removes stakes

‚ñ° **Risk/Reward Balance:** Do players take risks despite consequences?
- Should see: Calculated risks, push-your-luck gameplay
- Red flag: Players always play safe (too punishing) OR always aggressive (no stakes)

‚ñ° **Dread Maintenance:** Does resource scarcity create ongoing worry?
- Should see: Players planning ahead, conserving resources
- Red flag: Abundance removes tension

**Tension Aesthetic Success Criteria:**
- Strategic to extreme scarcity maintained
- Slow to no recovery (attrition)
- Losses feel significant but not unfair
- Pressure builds across session

### Submission Aesthetic Validation

**Core requirement: Resources don't create stress or complexity**

‚ñ° **Abundance Comfort:** Do players feel resourced, not constrained?
- Should see: Comfortable play, no anxiety
- Red flag: Resource scarcity creating stress

‚ñ° **Simplicity Test:** Are resources easy to track?
- Should see: Players rarely checking resource state
- Red flag: Constant tracking, cognitive overhead

‚ñ° **Non-Punishing:** Do resource mistakes have minimal consequences?
- Should see: Forgiving design, no harsh penalties
- Red flag: Mistakes feel punishing

‚ñ° **Automation Possibility:** Could resource management be automated?
- Should see: Simple patterns, predictable flows
- Red flag: Complex decisions required frequently

‚ñ° **Stress Absence:** Do resources create relaxation, not tension?
- Should see: Players describing game as "chill", "relaxing"
- Red flag: Players expressing stress about resources

**Submission Aesthetic Success Criteria:**
- Comfortable abundance (no scarcity stress)
- Minimal tracking overhead (2-3 simple resources)
- Forgiving consequences
- Resources support flow state, don't interrupt

### Narrative Aesthetic Validation

**Core requirement: Resources don't distract from story**

‚ñ° **Minimal Complexity:** Are resources simple and few?
- Should see: 1-2 resources max, simple tracking
- Red flag: Complex resource management pulling attention from narrative

‚ñ° **Narrative Integration:** Do resources support story, not contradict?
- Should see: Resource state reflecting narrative situation
- Red flag: Resource mechanics disconnected from story

‚ñ° **Non-Blocking:** Do resources never gate story progress?
- Should see: Story always accessible, resources optional depth
- Red flag: Resource scarcity preventing narrative advancement

‚ñ° **Invisible When Possible:** Can players ignore resources if desired?
- Should see: Resources supporting but not requiring engagement
- Red flag: Mandatory resource management interrupting story

‚ñ° **Thematic Resonance:** Do resources reinforce narrative themes?
- Should see: Resource names, functions align with story
- Red flag: Generic resource names (HP, mana) in narrative-focused game

**Narrative Aesthetic Success Criteria:**
- Minimal resource count and complexity
- Resources support narrative, don't block it
- Optional engagement (can ignore if story-focused)
- Thematic integration where resources exist

### Progression Aesthetic Validation

**Core requirement: Resources demonstrate growth and advancement**

‚ñ° **Visible Growth:** Do resources increase over time?
- Should see: Accumulation curves rising, power increasing
- Red flag: Flat resource curves (no growth feeling)

‚ñ° **Satisfying Milestones:** Do resource thresholds create achievement moments?
- Should see: Excitement at level-ups, unlocks
- Red flag: Gradual growth without notable milestones

‚ñ° **Power Curve:** Does resource growth translate to increased capability?
- Should see: Players becoming more powerful, handling harder challenges
- Red flag: Growth doesn't affect gameplay

‚ñ° **Meta-Persistence:** Do resources carry over between sessions?
- Should see: Long-term investment, return motivation
- Red flag: Reset each session (no progression persistence)

‚ñ° **Balance Maintenance:** Does progression avoid trivializing challenges?
- Should see: Difficulty scales with player power
- Red flag: Late-game triviality (too powerful) or brick walls (underscaled)

**Progression Aesthetic Success Criteria:**
- Clear accumulation and growth
- Satisfying milestones and unlocks
- Power increase feels meaningful
- Meta-resources persist across sessions
- Progression maintains challenge (see Chapter 4: Balance)

---

## Part 9: Red Flag Summary‚ÄîKnow When to Redesign

Some problems indicate minor tuning needed. Others indicate fundamental design failures requiring redesign.

### Minor Tuning Needed (Adjust Parameters)

**Indicators:**
- Resource too scarce/abundant but function is clear
- Recovery speed slightly off pacing target
- Costs/values need rebalancing
- One option in multiple-choice slightly dominates

**Solution approach:**
- Adjust numerical parameters (amounts, costs, recovery rates)
- Rebalance option values
- Fine-tune scarcity levels
- Iterate with small changes, test each

**Time investment:** Low (hours to days)

### Moderate Redesign Needed (Change Approach)

**Indicators:**
- Resource creates decisions but players find them tedious
- Tracking overhead too high for aesthetic
- Wrong behavior pattern for function (e.g., Accumulation when need Consumable)
- Resource interactions confusing

**Solution approach:**
- Change resource behavior pattern
- Simplify interaction mechanics
- Reduce resource count
- Improve clarity and feedback

**Time investment:** Moderate (days to weeks)

### Major Redesign Needed (Fundamental Failure)

**Indicators:**
- Players ignore resource entirely
- Resource creates no decisions
- Resource blocks core gameplay/narrative
- Configuration incoherence (resource contradicts aesthetic)
- Players actively frustrated by resource

**Solution approach:**
- Remove resource entirely, or
- Complete redesign of function and implementation
- Reconsider whether resource serves aesthetic

**Time investment:** High (weeks to months)

### Red Flags Requiring Immediate Redesign

These indicate critical failures‚Äîstop, redesign before continuing:

üö© **"I didn't know that resource existed"**
- Complete visibility failure
- Resource is non-functional
- Remove or make central to gameplay

üö© **"Why am I tracking this?"**
- Resource creates no decisions
- Pure busywork
- Remove immediately

üö© **"This feels unfair/broken"**
- Resource blocking content, creating frustration
- Fundamental mismatch with aesthetic
- Redesign or remove

üö© **"I can't tell what's happening"**
- Information opacity preventing decisions
- Either fix clarity or simplify drastically

üö© **Players spending 60+ seconds on simple decisions**
- Analysis paralysis from unclear value
- Reduce complexity or improve information

üö© **Resource curve trending wrong direction consistently**
- Abundance when want scarcity (or vice versa)
- Death spirals, broken economies
- Fundamental balance problem requiring redesign

üö© **Aesthetic incoherence**
- Scarce resources in Submission game (stress)
- Abundant resources in Challenge game (no decisions)
- Complex tracking in Narrative game (distraction)
- Configuration failure‚Äîresource contradicts aesthetic

---

## Part 10: Validation Documentation Template

After each playtest session, document findings systematically. This creates knowledge base for iteration.

### Session Documentation Template

**Session ID:** ___________ **Date:** ___________ **Duration:** ___________

**Playtesters:** (Number, experience level, player type)
- Casual / Midcore / Hardcore
- First-time / Experienced with this game / Experienced with genre

**Resources Being Tested:** (List all)
1. _______________
2. _______________
3. _______________

**Test Focus:** (What specific hypotheses being validated?)
- _______________________________________________
- _______________________________________________

**Quantitative Data Collected:**

| Resource | Start Amount | End Amount | Depletion Events | Avg Decision Time | Interaction Frequency |
|----------|--------------|------------|------------------|-------------------|-----------------------|
|          |              |            |                  |                   |                       |
|          |              |            |                  |                   |                       |

**Resource State Over Time:**
(Graph or table showing resource quantities at 5-minute intervals)

**Qualitative Observations:**

**Resource Awareness:**
- Resources players mentioned unprompted: _______________
- Resources players forgot: _______________
- Confusion about: _______________

**Decision Quality:**
- Hard decisions mentioned: _______________
- Obvious decisions mentioned: _______________
- Analysis paralysis moments: _______________

**Emotional Responses:**
- Satisfaction moments: _______________
- Frustration moments: _______________
- Tension moments: _______________
- Boredom moments: _______________

**Spontaneous Player Comments:** (Direct quotes)
- "_______________________________________________"
- "_______________________________________________"
- "_______________________________________________"

**Post-Session Interview Responses:**
(Key answers to interview questions)

**Aesthetic Validation:**
- Did resources create intended experience? YES / PARTIAL / NO
- Which aesthetic goals achieved: _______________
- Which aesthetic goals failed: _______________

**Problems Identified:**

| Problem | Severity (Minor/Moderate/Major) | Suspected Cause | Proposed Solution |
|---------|----------------------------------|-----------------|-------------------|
|         |                                  |                 |                   |
|         |                                  |                 |                   |

**Successes Identified:**
- _______________________________________________
- _______________________________________________

**Changes for Next Iteration:**
1. _______________________________________________
2. _______________________________________________
3. _______________________________________________

**Hypothesis Validation:**
- Hypothesis 1: VALIDATED / REJECTED / UNCERTAIN
- Hypothesis 2: VALIDATED / REJECTED / UNCERTAIN

**Confidence Level After Session:**
- Resource 1: HIGH / MEDIUM / LOW confidence in design
- Resource 2: HIGH / MEDIUM / LOW confidence in design

**Next Steps:**
- [ ] Minor tuning needed (adjust parameters)
- [ ] Moderate redesign needed (change approach)
- [ ] Major redesign needed (fundamental failure)
- [ ] Ready for next validation phase
- [ ] Ready for production

---

## Part 11: Iteration Framework

Playtesting isn't one-and-done. Effective validation requires multiple iterations with progressive refinement.

### Iteration Cycle

**Phase 1: Concept Validation (1-2 sessions)**
**Goal:** Does basic resource concept work at all?
**Test:** Core function, basic scarcity level, primary decisions
**Players:** Designers or close colleagues (understand what you're testing)
**Success criteria:** Resource creates ANY meaningful decisions
**Failure mode:** Resource ignored, confusing, or pointless ‚Üí Redesign

**Phase 2: Experience Validation (3-5 sessions)**
**Goal:** Does resource create intended aesthetic experience?
**Test:** Emotional response, pacing effects, aesthetic alignment
**Players:** Target audience representatives (casual/midcore/hardcore)
**Success criteria:** Resources produce intended feelings and behaviors
**Failure mode:** Wrong aesthetic response ‚Üí Tune or redesign

**Phase 3: Balance Validation (5-10 sessions)**
**Goal:** Are resource parameters correct?
**Test:** Scarcity levels, recovery speeds, cost balancing
**Players:** Varied skill levels within target audience
**Success criteria:** Resources balanced across player skill range
**Failure mode:** Too easy/hard for some players ‚Üí Tune parameters or add difficulty options

**Phase 4: Integration Validation (10+ sessions)**
**Goal:** Do resources work with full game systems?
**Test:** Multi-resource economies, cross-system interactions, full-session balance
**Players:** Full target audience spectrum
**Success criteria:** Resources maintain relevance throughout play, no exploits
**Failure mode:** Resources break under full complexity ‚Üí Simplify or redesign interactions

**Phase 5: Scale Validation (20+ sessions)**
**Goal:** Does resource design hold across many players and playstyles?
**Test:** Edge cases, emergent strategies, long-term balance
**Players:** Broad testing (including antagonistic players trying to break systems)
**Success criteria:** Design robust to varied playstyles, no major exploits
**Failure mode:** Edge cases break design ‚Üí Add safeguards or redesign

### When to Move Between Phases

**Advance to next phase when:**
- All critical problems in current phase solved
- Success criteria for current phase met consistently (3+ sessions in a row)
- Confidence level HIGH for tested aspects

**Return to previous phase when:**
- Fundamental problems discovered (resource not creating decisions)
- Aesthetic mismatch found (wrong emotional response)
- New iteration requires re-testing basics

**Start over at Phase 1 when:**
- Complete redesign required
- New resource added
- Fundamental system change affects resource

### Efficiency Tips

**Parallel testing:**
- Can test multiple resources simultaneously in Phase 1-2
- But isolate resources in Phase 3-4 to identify specific problems
- Return to full integration in Phase 5

**Incremental changes:**
- Change one variable at a time when tuning
- Document each change and resulting effect
- Makes cause-and-effect clear

**Hypothesis-driven:**
- State clear hypothesis before each session
- "Reducing gold acquisition by 30% will create strategic scarcity"
- Validate or reject hypothesis explicitly
- Prevents aimless iteration

**Know when to stop:**
- Diminishing returns after successful Phase 5
- Perfect is enemy of good
- When playtests show consistent success and no critical problems, ship it

---

## Part 12: Quick Reference Validation Checklists

### 5-Minute Resource Health Check

Quick assessment during any playtest‚Äîwatch for these signals:

**HEALTHY RESOURCE SIGNS:**
‚úÖ Players mention resource unprompted when planning
‚úÖ Players express mild tension about running out
‚úÖ Players debate for 10-30 seconds before spending
‚úÖ Players verbalize trade-offs ("If I do X, I can't do Y")
‚úÖ Players show satisfaction when good spending pays off
‚úÖ Players can recall approximate resource state without checking

**UNHEALTHY RESOURCE SIGNS:**
‚ùå Players never mention resource
‚ùå Players express frustration or anger about resource
‚ùå Players decide instantly (no deliberation) or take 60+ seconds
‚ùå Players say "I can do everything" or "I can do nothing"
‚ùå Players show no emotional response to resource changes
‚ùå Players constantly ask "How much [resource] do I have?"

### Essential Questions for Every Resource

Ask yourself these after EVERY playtest:

1. **Awareness:** "Did players notice this resource exists?"
2. **Understanding:** "Did players grasp what this resource does?"
3. **Decisions:** "Did this resource create any meaningful choices?"
4. **Aesthetic:** "Did this resource create the intended emotional experience?"
5. **Worth:** "Was tracking this resource worth the cognitive overhead?"

If answer to ANY question is "No" ‚Üí Problem requires addressing before proceeding.

### Pre-Production Validation Checklist

Before committing to production, validate ALL of these:

**Functional Validation:**
‚ñ° Resource function clear to players within 15 minutes
‚ñ° Resource creates decisions, not busywork
‚ñ° Resource integrates with other systems without breaking
‚ñ° Resource tracking manageable within cognitive budget

**Aesthetic Validation:**
‚ñ° Resource produces intended emotional response
‚ñ° Resource supports primary aesthetic (doesn't contradict)
‚ñ° Resource pacing aligns with overall game pacing
‚ñ° Resource scarcity/abundance matches aesthetic needs

**Balance Validation:**
‚ñ° Resource remains relevant throughout entire session/campaign
‚ñ° No exploits or dominant strategies
‚ñ° Resource viable across different player skill levels
‚ñ° Resource recovery rate creates intended pacing pattern

**Technical Validation:**
‚ñ° Resource state saves/loads correctly (if applicable)
‚ñ° Resource UI clear and accessible
‚ñ° Resource calculations performant (no lag)
‚ñ° Resource interactions debugged and stable

**Player Validation:**
‚ñ° Target audience can track resource comfortably
‚ñ° Multiple playstyles viable (not one optimal approach)
‚ñ° Learning curve appropriate for target audience
‚ñ° Player feedback consistently positive on resource

**Production Readiness:**
‚ñ° Resource design stable (no major changes planned)
‚ñ° All critical problems solved
‚ñ° Edge cases identified and handled
‚ñ° Documentation complete for implementation team

---

## Conclusion: Validation as Continuous Process

Resource validation isn't a phase you complete and move on from. It's an ongoing process of:

1. **Hypothesis** - "This resource should create this experience"
2. **Test** - Playtest with specific observation goals
3. **Measure** - Collect quantitative and qualitative data
4. **Diagnose** - Identify what's working and what's broken
5. **Iterate** - Make targeted changes
6. **Repeat** - Test again until validated

**Remember:**
- Start with clear design intentions (Chapter 2 frameworks)
- Test against those intentions, not vague "fun"
- Use both numbers and player feedback
- Iterate systematically, change one thing at a time
- Know when to tune vs. when to redesign
- Validate at multiple scales (concept ‚Üí experience ‚Üí balance ‚Üí integration)

**The goal isn't perfect resources‚Äîit's resources that reliably create your intended experience.**

When playtests consistently show:
- Players understand resources
- Resources create intended decisions
- Resources produce intended emotions
- Resources integrate coherently with systems
- Target audience enjoys the experience

Then your resources are validated and ready for production.

**Good luck, and remember: Playtest early, playtest often, and always playtest with clear hypotheses.**

---

*This validation framework designed to complement Chapter 2: Resource Management*
*Use in conjunction with Chapter 3 (Cognitive Load) and Chapter 4 (Balance) validation protocols*
*For integration with overall game system validation, see Synthesis Chapter frameworks*
